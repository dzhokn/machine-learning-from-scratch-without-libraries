{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c19b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7e3f17",
   "metadata": {},
   "source": [
    "# 1. Convolution\n",
    "#### 1.1 What is a convolution?\n",
    "\n",
    "Say I give you the coefficients of polynomials $P$ and $Q$. If I give you $x$, there are two ways to evaluate $P(x)*Q(x)$ :\n",
    "\n",
    "1. Evaluate $P(x)$ and $Q(x)$, and multiply them together; or\n",
    "2. Expand $PQ$ into a bigger polynomial, then evaluate it at $x$.\n",
    "\n",
    "In the first case, what you do to $P(x)$ and $Q(x)$ is called **multiplication**. In the second case, what you do to the coefficients of $P$ and $Q$ to get the coefficients of $PQ$ is called (discrete) **convolution**.\n",
    "\n",
    "As we have seen, multiplication and convolution can often be used to get the same results through different methods.\n",
    "\n",
    "\n",
    "* $ P(x) = 7 - 2x + 4x^2 $\n",
    "* $ Q(x) = 3 + x - 2x^2 $\n",
    "* $ x = 1 $\n",
    "\n",
    "**Approach 1**: \n",
    "$$(7 - 2 + 4).(3 + 1 - 2) = $$\n",
    "$$= 9 . 2 $$\n",
    "$$ = 18$$\n",
    "**Approach 2**: \n",
    "$$(7 - 2x + 4x^2).(3 + x - 2x^2) = $$\n",
    "$$ = (21) + (7x-6x) + (-14x^2 + 12x^2 - 2x^2) + (4x^3 + 4x^3) + (-8x^4) $$\n",
    "$$ = (21) + (x) + (-4x^2) + (8x^3) + (-8x^4) $$\n",
    "$$ = 18$$\n",
    "\n",
    "#### 1.2 Weighted average of a function\n",
    "In calculating a simple average all numbers are treated equally and assigned equal weight. But a weighted average assigns weights that determine in advance the relative importance of each data point. In calculating a **weighted average**, each number in the data set is multiplied by a predetermined weight before the final calculation is made.\n",
    "\n",
    "| Data point | Value | Weight | Weighted value |\n",
    "| --- | --- | --- | --- |\n",
    "| 1 | 10 | 2 | 20 |\n",
    "| 2 | 50 | 5 | 250 |\n",
    "| 3 | 40 | 3 | 120 |\n",
    "| **TOTAL** | 100 | 10 | 390 |\n",
    "| **Weighted Avg** |  |  | 39 |\n",
    "\n",
    "#### 1.3 Convolution - second explanation\n",
    "Given two weighted dice with following probability distribution:\n",
    "\n",
    "<center><img src=\"img/convolution_0.png\" alt=\"Two weighted dices\" width=\"800\" height=\"424\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 1.</b> Two unfair (weighted) dice </i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "Convolution would be applying one of the function over the other and getting as a result a new function with new probability distribution.\n",
    "<center><img src=\"img/convolution_1.png\" alt=\"Convolution of probability functions\" width=\"800\" height=\"191\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 2.</b> Convolution of probability functions </i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "In order to get the polynomial of the new function, the easiest would be to **FLIP** the second distribution (kernel).\n",
    "<center><img src=\"img/convolution_2.png\" alt=\"Flip the kernel\" width=\"400\" height=\"508\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 3.</b> Flip the second distribution (kernel) </i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "And now we can easily calculate each probability of the new function by executing a **dot product** between the respective terms and then slide the kernel to the right.\n",
    "<center><img src=\"img/convolution_3.png\" alt=\"Multiply and slide\" width=\"800\" height=\"423\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 4.</b> Multiply and slide right </i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "So, we end up with next formula.\n",
    "<center><img src=\"img/convolution_4.png\" alt=\"Convolution formula\" width=\"800\" height=\"436\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 5.</b> Convolution formula</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339d8604",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.4 Formula\n",
    "* The **discrete** formula looks like this:\n",
    "```\n",
    "y[n] = Σ x[k] * h[n - k]\n",
    "```\n",
    "or more formally:\n",
    "$$[f*g](s) = \\sum f(x) \\cdot g(s-x) $$\n",
    "\n",
    "Considering the general rule of thumb:\n",
    "$$\\sum \\text{... } \\rightarrow \\int \\text{... }dx$$\n",
    "\n",
    "* The **continious** formula would be:\n",
    "\n",
    "$$[f*g](s) = \\int_{-\\infty}^{\\infty} f(x) \\cdot g(s-x) dx$$\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "It’s easiest if you assume one of the functions is a probability density function $P$ centered at the origin. Then the convolution of $P$ with a function $Q$ at each $x$ is the weighted average of $Q$, using $P$ as the weight function centered at $x$. This clearly creates a **smooth approximation** of $Q$ where the random noise in $Q$ is averaged out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d43bfb7",
   "metadata": {},
   "source": [
    "# 2. Convolution operation\n",
    "\n",
    "Convolution between two matrices is a simple operation. You simply need to multiply the `input` matrix to a smaller `kernel` matrix in a specific way.\n",
    "\n",
    "\n",
    "But before that, you need to **flip** the kernel (i.e. reflect its content across the center).\n",
    "\n",
    "* NB: If not flipped, then we are not doing a **convolution**, but a **cross-correlation**.\n",
    "\n",
    "<center><img src=\"img/cnn_0.png\" alt=\"Convolution between two matrices\" width=\"600\" height=\"262\" /></center>\n",
    "<center><img src=\"img/cnn_1.png\" alt=\"Convolution between two matrices\" width=\"600\" height=\"259\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 6.</b> Convolution between two matrices</i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "We start from the upper-left corner of the `input` matrix. And we multiply each cell from the `input` to the corresponding cell into the `kernel` matrix. And we sum the result. This way we calculate the first cell of the `output` matrix.\n",
    "<center><img src=\"img/cnn_2.png\" alt=\"Multiply a submatrix from the `input` to the `kernel`\" width=\"600\" height=\"372\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 7.</b> Multiply a submatrix from the `input` to the `kernel`</i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "Then we slide the window to the right and calculate the next `output` cell.\n",
    "<center><img src=\"img/cnn_3.png\" alt=\"Slide the calculation window to the right\" width=\"600\" height=\"362\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 8.</b> Slide the calculation window to the right</i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "Once we can't slide more to the right, we go one row down and start over from the leftest cell.\n",
    "<center><img src=\"img/cnn_4.png\" alt=\"One row down and start again from the leftest cell\" width=\"600\" height=\"371\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 9.</b> One row down and start again from the leftest cell</i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "* **Size of the output**\n",
    "\n",
    "The size of the output matrix is calculated as:\n",
    "$$ O = I - K + 1 $$\n",
    "where $I$ is the size of the `input` matrix and $K$ is the size of the `kernel` matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c217bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate2d(image: np.ndarray, kernel: np.ndarray, mode: str = 'valid') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the correlation of the image with the kernel.\n",
    "    The correlation is a measure of how similar two signals are.\n",
    "    In the context of image processing, the correlation is used to find the features in the image.\n",
    "    The correlation is calculated by multiplying the kernel with the image cell by cell and summing the result.\n",
    "    The output is a matrix of the same size as the image.\n",
    "    The mode parameter determines the shape of the output matrix.\n",
    "    - 'full' mode: the output matrix is the same size as the image.\n",
    "    - 'valid' mode: the output matrix is the same size as the image minus the kernel size.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The input image.\n",
    "        kernel (np.ndarray): The kernel.\n",
    "        mode (str): The mode of the correlation.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The output matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the shape of the kernel and image\n",
    "    m, n = kernel.shape\n",
    "    y, x = image.shape\n",
    "\n",
    "    # CASE 1: Full mode - output shape is (y + m - 1, x + n - 1)\n",
    "    if mode == 'valid':\n",
    "        # SLOW IMPLEMENTATION (not vectorized)\n",
    "        # for i in range(y - m + 1):\n",
    "        #     for j in range(x - n + 1):\n",
    "        #         output[i, j] = (image[i:i+m, j:j+n] * kernel).sum()\n",
    "\n",
    "        # FAST IMPLEMENTATION (vectorized)\n",
    "        output = einsum_submatrices(image, kernel, x-n+1, y-m+1, m, n)\n",
    "    \n",
    "    # CASE 2: Valid mode - output shape is (y - m + 1, x - n + 1)\n",
    "    elif mode == 'full':\n",
    "        # Add padding to the input image\n",
    "        image = np.pad(image, ((m-1, m-1), (n-1, n-1)), mode='constant', constant_values=0)\n",
    "        output = einsum_submatrices(image, kernel, x+n-1, y+m-1, m, n)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid mode: {mode}\")\n",
    "    return output\n",
    "\n",
    "def einsum_submatrices(image: np.ndarray, kernel: np.ndarray, width: int, height: int, m: int, n: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate submatrices of the image in order to use np.einsum.\n",
    "    The submatrices are generated by sliding the kernel over the image.\n",
    "    The submatrices are then multiplied with the kernel and the result is summed.\n",
    "    The result is a matrix of the same size as the image.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The input image.\n",
    "        kernel (np.ndarray): The kernel.\n",
    "        width (int): The width of the output matrix.\n",
    "        height (int): The height of the output matrix.\n",
    "        m (int): The number of rows of the kernel.\n",
    "        n (int): The number of columns of the kernel.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    submatrices = []\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            submatrices.append(image[i:i+m, j:j+n])\n",
    "    submatrices = np.array(submatrices)\n",
    "    submatrices = submatrices.reshape(height, width, m, n)\n",
    "    # Multiply the submatrices with the kernel\n",
    "    # np.einsum is a function that allows you to perform a dot product between two arrays.\n",
    "    # It is a more efficient way to perform the dot product than using a for loop.\n",
    "    # It is also more readable and concise.\n",
    "    # Generate submatrices of the image in order to use np.einsum\n",
    "    return np.einsum('ijkl,kl->ij', submatrices, kernel)\n",
    "\n",
    "def convolve2d(image: np.ndarray, kernel: np.ndarray, mode: str = 'valid') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convolve the image with the kernel.\n",
    "    \"\"\"\n",
    "    # Flip the kernel\n",
    "    kernel = np.flip(kernel)\n",
    "    return correlate2d(image, kernel, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328ddd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4 -4]\n",
      " [-4 -4]]\n",
      "[[4 4]\n",
      " [4 4]]\n",
      "\n",
      "[[-1 -2 -3  0]\n",
      " [-4 -4 -4  3]\n",
      " [-7 -4 -4  6]\n",
      " [ 0  7  8  9]]\n",
      "[[ 1  2  3  0]\n",
      " [ 4  4  4 -3]\n",
      " [ 7  4  4 -6]\n",
      " [ 0 -7 -8 -9]]\n"
     ]
    }
   ],
   "source": [
    "test_input = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "# Kernel (filter)\n",
    "test_kernel = np.array([\n",
    "    [1, 0],\n",
    "    [0, -1]\n",
    "])\n",
    "\n",
    "print(correlate2d(test_input, test_kernel, mode='valid'))\n",
    "print(convolve2d(test_input, test_kernel, mode='valid'))\n",
    "print('')\n",
    "print(correlate2d(test_input, test_kernel, mode='full'))\n",
    "print(convolve2d(test_input, test_kernel, mode='full'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d10673",
   "metadata": {},
   "source": [
    "# 3. Convolutional Neural Network\n",
    "\n",
    "#### 3.1 Convolutional layer\n",
    "\n",
    "* **The input** is a 3-dimensional block of data (e.g. image tensor). In this case the depth is 3.\n",
    "* **The weights** are organized as kernels (a 3-dimensional block with the same depth as the input). The layer may have one or multiple kernels.\n",
    "* **The bias matrices** have the same shape as the outputs. The number of biases is equal to the number of kernels in the layer.\n",
    "* **The output** is a 3-dimensional block of data. The depth of the output is the same as the number of kernels.\n",
    "\n",
    "<center><img src=\"img/cnn_5.png\" alt=\"Convolutional layer with 2 kernels\" width=\"800\" height=\"404\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 10.</b> Convolutional layer with 2 kernels</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86746bcd",
   "metadata": {},
   "source": [
    "First, let's create an abstract class, which will further be used for any kind of layers in our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a83db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        # TODO: return output\n",
    "        pass\n",
    "\n",
    "    def backward(self, output_gradient: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        # TODO: update parameters and return input gradient\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d7828",
   "metadata": {},
   "source": [
    "Now, let's create the **convolutional layer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b4993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, kernel_size: int, num_of_kernels: int):\n",
    "        \"\"\"\n",
    "        Initialize the convolutional layer.\n",
    "        The layer will be initialized with random weights and biases.\n",
    "\n",
    "        The shape of the output is calculated as:\n",
    "         * output_shape = (num_of_kernels, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
    "         * kernel_shape = (num_of_kernels, input_depth, kernel_size, kernel_size)\n",
    "         * biases_shape = (output_shape)\n",
    "\n",
    "        Args:\n",
    "            input_shape: tuple, shape of the input data (depth, height, width)\n",
    "            kernel_size: int, size of the kernel (e.g. 4 for 4x4 kernel)\n",
    "            num_of_kernels: int, number of kernels in the layer (e.g. 2 for 2 kernels)\n",
    "        \"\"\"\n",
    "        input_depth, input_height, input_width = input_shape                            # (e.g. 3, 28, 28)\n",
    "        self.num_of_kernels = num_of_kernels                                            # (e.g. 2)\n",
    "        self.input_shape = input_shape                                                  # (e.g. 3, 28, 28)\n",
    "        self.kernel_shape = (num_of_kernels, input_depth, kernel_size, kernel_size)     # (e.g. 2, 3, 4, 4)\n",
    "        self.output_shape = (num_of_kernels, input_height - kernel_size + 1, input_width - kernel_size + 1) # (e.g. 2, 25, 25)\n",
    "\n",
    "        # Generate random weights and biases\n",
    "        self.kernels = np.random.randn(*self.kernel_shape)  # (e.g. 2, 3, 4, 4)\n",
    "        self.biases = np.random.randn(*self.output_shape)   # (e.g. 2, 25, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d7d1d",
   "metadata": {},
   "source": [
    "#### 3.2 Forward propagation\n",
    "**How the output is produced?**\n",
    "\n",
    "Take each matrix in the first kernel and compute the cross-correlation with the input data. Sum the three results and add up the first bias. This will produce the first output.\n",
    "\n",
    "\n",
    "<center><img src=\"img/cnn_6.png\" alt=\"Convolutional layer - how the output is produced\" width=\"800\" height=\"467\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 11.</b> Convolutional layer - how the output is produced</i></p>\n",
    "\n",
    "After that go on in the same manner for the next cells in this output matrix.\n",
    "\n",
    "\n",
    "Likewise, the second output is calculated by cross-correlating the input with the second kernel and second bias.\n",
    "\n",
    "\n",
    "<center><img src=\"img/cnn_7.png\" alt=\"Convolutional layer - the second output is produced in the same way, but using the second kernel\" width=\"800\" height=\"468\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 12.</b> Convolutional layer - the second output is produced in the same way, but using the second kernel</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47243107",
   "metadata": {},
   "source": [
    "We can simplify the formula to:\n",
    "$$Y_1 = B_1 + X_1 \\star K_{11} + X_2 \\star K_{12} + X_3 \\star K_{13} $$\n",
    "$$Y_2 = B_2 + X_2 \\star K_{21} + X_2 \\star K_{22} + X_3 \\star K_{23} $$\n",
    "$$ \\vdots $$\n",
    "$$Y_d = B_d + X_1 \\star K_{d1} + X_2 \\star K_{d2} + X_3 \\star K_{d3} $$\n",
    "\n",
    "Where $d$ is the the number of kernels (hence the depth of the outputs).\n",
    "\n",
    "\n",
    "\n",
    "<center><img src=\"img/cnn_8.png\" alt=\"Convolutional layer - the output formula (simplified)\" width=\"400\" height=\"227\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 13.</b> Convolutional layer - the output formula (simplified)</i></p>\n",
    "\n",
    "And if we generalize the shape of the input, we come up with following formula:\n",
    "\n",
    "$$Y_d = B_d + X_1 \\star K_{d1} + X_2 \\star K_{d2} + \\dots + X_n \\star K_{dn} $$\n",
    "\n",
    "or\n",
    "\n",
    "$$ Y_i = B_i + \\sum_{j=1}^{n}{X_j \\star K_{ij}} \\text{  ,  } i = 1 \\dots d$$\n",
    "\n",
    "Where $n$ is the depth of the input and $d$ is the number of kernels.\n",
    "\n",
    "\n",
    "If we go further, we will see a similarity between a regular dense layer and a convolutional layer. The only difference is that in the dense layer we calculate **dot product** between **matrices of scalar values**, while here we calculate **cross-correlated dot product** between **matrices of matrices**. But in general the dense layer is a subtype of the convolutional layer.\n",
    "\n",
    "<center><img src=\"img/cnn_9.png\" alt=\"Convolutional layer looks the same as a dense layer\" width=\"800\" height=\"288\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 14.</b> Convolutional layer looks very similar to a regular dense layer</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76ea1763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Forward pass through the convolutional layer.\n",
    "        - The input is a 3D tensor (e.g. image tensor).\n",
    "        - The output is a 3D tensor (e.g. feature map).\n",
    "\n",
    "    The formula is:\n",
    "        - Y_i = B_i + \\\\sum_{j=1}^{n}{X_j \\\\star K_{ij}}\n",
    "    where:\n",
    "        - Y_i is the output of the i-th kernel\n",
    "        - B_i is the bias of the i-th kernel\n",
    "        - X_j is the j-th depth of the input\n",
    "        - K_{ij} is the j-th depth of the i-th kernel\n",
    "        - n is the number of depths of the input\n",
    "\n",
    "    Args:\n",
    "        input: np.ndarray, input tensor (e.g. image tensor)\n",
    "    Returns:\n",
    "        np.ndarray, output tensor (e.g. feature map)\n",
    "    \"\"\"\n",
    "    self.input = input\n",
    "    self.output = np.copy(self.biases)\n",
    "\n",
    "    # For each kernel (e.g. 2)\n",
    "    for i in range(self.number_of_kernels): \n",
    "        # For each depth of the input (e.g. 3)\n",
    "        for j in range(self.input_shape[0]):\n",
    "            # The formula is:\n",
    "            # - output[i] += input[j] * kernels[i, j]\n",
    "            # where:\n",
    "            # - output[i] is the output of the i-th kernel\n",
    "            # - input[j] is the j-th depth of the input\n",
    "            # - kernels[i, j] is the j-th depth of the i-th kernel\n",
    "            # - mode='valid' is the mode of the correlation operation\n",
    "            self.output[i] += correlate2d(self.input[j], self.kernels[i, j], mode='valid')\n",
    "\n",
    "    # Return the output of the layer\n",
    "    return self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961a8c9",
   "metadata": {},
   "source": [
    "#### 3.3 Backward propagation\n",
    "\n",
    "We need to calculate the following derivatives:\n",
    "$$\\frac{dJ}{dK_{ij}}, \\frac{dJ}{dB_i}, \\frac{dJ}{dX_j} $$\n",
    "\n",
    "And after applying several *chain rules* and some math mojo we come up with next formulas:\n",
    "$$\\frac{dJ}{dK_{ij}} = X_j \\star \\frac{dJ}{dY_{i}}$$\n",
    "$$\\frac{dJ}{dB_i} = \\frac{dJ}{dY_{i}}$$\n",
    "$$\\frac{dJ}{dX_j} = \\sum_{i=1}^d {\\frac{dJ}{dY_{i}} \\ast_{full} }K $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63c4662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, output_gradient: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Backward pass through the convolutional layer.\n",
    "\n",
    "    Args:\n",
    "        output_gradient: np.ndarray, the gradient of the output (e.g. [[1, 2, 3], [4, 5, 6]])\n",
    "        learning_rate: float, the learning rate\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray, the gradient of the input (e.g. [1, 2, 3, 4, 5, 6])\n",
    "    \"\"\"\n",
    "    kernels_gradient = np.zeros(self.kernel_shape)\n",
    "    input_gradient = np.zeros(self.input_shape)\n",
    "\n",
    "    for i in range(self.num_of_kernels):\n",
    "        for j in range(self.input_shape[0]): # input depth\n",
    "            kernels_gradient[i, j] = correlate2d(self.input[j], output_gradient[i], mode='valid')\n",
    "            input_gradient[j] += convolve2d(output_gradient[i], self.kernels[i, j], mode='full')\n",
    "\n",
    "    self.kernels -= learning_rate * kernels_gradient\n",
    "    self.biases -= learning_rate * output_gradient\n",
    "\n",
    "    return input_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c4790b",
   "metadata": {},
   "source": [
    "So, finally, the class will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d63ed094",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, kernel_size: int, num_of_kernels: int):\n",
    "        \"\"\"\n",
    "        Initialize the convolutional layer.\n",
    "        The layer will be initialized with random weights and biases.\n",
    "\n",
    "        The shape of the output is calculated as:\n",
    "         * output_shape = (num_of_kernels, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
    "         * kernel_shape = (num_of_kernels, input_depth, kernel_size, kernel_size)\n",
    "         * biases_shape = (output_shape)\n",
    "\n",
    "        Args:\n",
    "            input_shape: tuple, shape of the input data (depth, height, width)\n",
    "            kernel_size: int, size of the kernel (e.g. 4 for 4x4 kernel)\n",
    "            num_of_kernels: int, number of kernels in the layer (e.g. 2 for 2 kernels)\n",
    "        \"\"\"\n",
    "        input_depth, input_height, input_width = input_shape                            # (e.g. 3, 28, 28)\n",
    "        self.num_of_kernels = num_of_kernels                                            # (e.g. 2)\n",
    "        self.input_shape = input_shape                                                  # (e.g. 3, 28, 28)\n",
    "        self.kernel_shape = (num_of_kernels, input_depth, kernel_size, kernel_size)     # (e.g. 2, 3, 4, 4)\n",
    "        self.output_shape = (num_of_kernels, input_height - kernel_size + 1, input_width - kernel_size + 1) # (e.g. 2, 25, 25)\n",
    "\n",
    "        # Generate random weights and biases\n",
    "        self.kernels = np.random.randn(*self.kernel_shape)  # (e.g. 2, 3, 4, 4)\n",
    "        self.biases = np.random.randn(*self.output_shape)   # (e.g. 2, 25, 25)\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Forward pass through the convolutional layer.\n",
    "            - The input is a 3D tensor (e.g. image tensor).\n",
    "            - The output is a 3D tensor (e.g. feature map).\n",
    "\n",
    "        The formula is:\n",
    "            - Y_i = B_i + \\\\sum_{j=1}^{n}{X_j \\\\star K_{ij}}\n",
    "        where:\n",
    "            - Y_i is the output of the i-th kernel\n",
    "            - B_i is the bias of the i-th kernel\n",
    "            - X_j is the j-th depth of the input\n",
    "            - K_{ij} is the j-th depth of the i-th kernel\n",
    "            - n is the number of depths of the input\n",
    "\n",
    "        Args:\n",
    "            input: np.ndarray, input tensor (e.g. image tensor)\n",
    "        Returns:\n",
    "            np.ndarray, output tensor (e.g. feature map)\n",
    "        \"\"\"\n",
    "        self.input = input\n",
    "        self.output = np.copy(self.biases) # Output = bias + sum(input * kernel)\n",
    "\n",
    "        # For each kernel (e.g. 2)\n",
    "        for i in range(self.num_of_kernels): \n",
    "            # For each depth of the input (e.g. 3)\n",
    "            for j in range(self.input_shape[0]):\n",
    "                # The formula is:\n",
    "                # - output[i] += input[j] * kernels[i, j]\n",
    "                # where:\n",
    "                # - output[i] is the output of the i-th kernel\n",
    "                # - input[j] is the j-th depth of the input\n",
    "                # - kernels[i, j] is the j-th depth of the i-th kernel\n",
    "                # - mode='valid' is the mode of the correlation operation\n",
    "                self.output[i] += correlate2d(self.input[j], self.kernels[i, j], mode='valid')\n",
    "\n",
    "        # Return the output of the layer\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_gradient: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Backward pass through the convolutional layer.\n",
    "\n",
    "        Args:\n",
    "            output_gradient: np.ndarray, the gradient of the output (e.g. [[1, 2, 3], [4, 5, 6]])\n",
    "            learning_rate: float, the learning rate\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray, the gradient of the input (e.g. [1, 2, 3, 4, 5, 6])\n",
    "        \"\"\"\n",
    "        kernels_gradient = np.zeros(self.kernel_shape)\n",
    "        input_gradient = np.zeros(self.input_shape)\n",
    "\n",
    "        for i in range(self.num_of_kernels):\n",
    "            for j in range(self.input_shape[0]): # input depth\n",
    "                kernels_gradient[i, j] = correlate2d(self.input[j], output_gradient[i], mode='valid')\n",
    "                input_gradient[j] += convolve2d(output_gradient[i], self.kernels[i, j], mode='full')\n",
    "\n",
    "        self.kernels -= learning_rate * kernels_gradient\n",
    "        self.biases -= learning_rate * output_gradient\n",
    "\n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b8190c",
   "metadata": {},
   "source": [
    "# 4. Reshape Layer\n",
    "\n",
    "This layer is needed since the output of a **convolutional layer** is a 3D block. While typically at the end of a network we use **dense layers**, which take in a column vector as an input. Therefore, we need a mechanism that reshapes data, hence the **reshape layer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "071ac865",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, output_shape: tuple):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Reshape the input to the output shape.\n",
    "\n",
    "        Args:\n",
    "            input: np.ndarray, the input to be reshaped (e.g. [1, 2, 3, 4, 5, 6])\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray, the reshaped input (e.g. [[1, 2, 3], [4, 5, 6]])\n",
    "        \"\"\"\n",
    "        return input.reshape(self.output_shape)\n",
    "\n",
    "    def backward(self, output_gradient: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Reshape the output gradient to the input shape.\n",
    "\n",
    "        Args:\n",
    "            output_gradient: np.ndarray, the gradient of the output (e.g. [[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray, the gradient of the input (e.g. [1, 2, 3, 4, 5, 6])\n",
    "        \"\"\"\n",
    "        return output_gradient.reshape(self.input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e481d0c",
   "metadata": {},
   "source": [
    "# 5. Dense layer\n",
    "We will add a standart **dense** (fully-conected) layer, which you should already know from all other neural networks, covered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ef1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(output_size, input_size)\n",
    "        self.bias = np.random.randn(output_size, 1)\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        self.input = input\n",
    "        # Return the standard output of the layer (weights * input + bias)\n",
    "        return np.dot(self.weights, self.input) + self.bias\n",
    "\n",
    "    def backward(self, output_gradient: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        # Calculate the weights gradient\n",
    "        weights_gradient = np.dot(output_gradient, self.input.T)\n",
    "        # Calculate the input gradient\n",
    "        input_gradient = np.dot(self.weights.T, output_gradient)\n",
    "        # Update the weights and bias\n",
    "        self.weights -= learning_rate * weights_gradient\n",
    "        self.bias -= learning_rate * output_gradient\n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a296a98",
   "metadata": {},
   "source": [
    "# 6. Cross Entropy Loss\n",
    "We'll prepare our **convolutional neural network** for classification task. Hence, we'll use the **cross entropy loss** formula.\n",
    "\n",
    "If this is the **actual** output of the network:\n",
    "$$ \\hat{Y} = \\begin{bmatrix}\\hat{y_1}\\\\\\hat{y_2}\\\\\\vdots\\\\\\hat{y_i}\\end{bmatrix}  ,  \\hat{y_i} \\in \\{0,1\\} $$\n",
    "\n",
    "And this is the **expected** one:\n",
    "$$ Y = \\begin{bmatrix}y_1\\\\y_2\\\\\\vdots\\\\y_i\\end{bmatrix} $$\n",
    "\n",
    "Then the **cross-entropy loss** formula would be:\n",
    "$$ J = -\\frac{1}{n} \\sum_{i=1}^{n} \\hat{y_i} log(y_i) + (1-\\hat{y_i}) log(1-y_i) $$\n",
    "\n",
    "Thus, the derivative of $J$ w.r.t to the **output** would be:\n",
    "$$ \\frac{dJ}{dY} = \\begin{bmatrix} \\frac{dJ}{dy_1} \\\\ \\frac{dJ}{dy_2} \\\\\\vdots\\\\ \\frac{dJ}{dy_i} \\end{bmatrix} \n",
    "= \\frac{1}{n} \\left(\\frac{1-\\hat{y_i}}{1-y_i} - \\frac{\\hat{y_i}}{y_i} \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9b1a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(Y_true: np.ndarray, Y_pred: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the cross-entropy loss.\n",
    "\n",
    "    Args:\n",
    "        Y_true: np.ndarray, the true labels (e.g. [0, 1, 0, 1, 0])\n",
    "        Y_pred: np.ndarray, the predicted labels (e.g. [0.1, 0.9, 0.1, 0.9, 0.1])\n",
    "\n",
    "    Returns:\n",
    "        float, the cross-entropy loss\n",
    "    \"\"\"\n",
    "    e = 1e-7 # Avoid log(0)\n",
    "    return -np.mean(Y_true * np.log(Y_pred + e) + (1 - Y_true) * np.log(1 - Y_pred + e))\n",
    "\n",
    "def cross_entropy_loss_derivative(Y_true: np.ndarray, Y_pred: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the derivative of the cross-entropy loss.\n",
    "\n",
    "    Args:\n",
    "        Y_true: np.ndarray, the true labels (e.g. [0, 1, 0, 1, 0])\n",
    "        Y_pred: np.ndarray, the predicted labels (e.g. [0.1, 0.9, 0.1, 0.9, 0.1])\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray, the derivative of the cross-entropy loss\n",
    "    \"\"\"\n",
    "    e = 1e-7 # Avoid division by zero\n",
    "    return ((1 - Y_true) / (1 - Y_pred + e) - Y_true / (Y_pred + e)) / np.size(Y_true) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a7df8a",
   "metadata": {},
   "source": [
    "# 7. Activation function\n",
    "In our case we would use a **sigmoid** function for activation. And let's pack it as a layer, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c5fc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation(Layer):\n",
    "    def __init__(self, activation, activation_derivative):\n",
    "        self.activation = activation\n",
    "        self.activation_derivative = activation_derivative\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        # Explanation:\n",
    "        # - self.input: the input of the layer\n",
    "        # - self.activation: the activation function\n",
    "        # - return: the output of the layer\n",
    "        return self.activation(self.input)\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        # Explanation:\n",
    "        # - output_gradient: the gradient of the output of the layer\n",
    "        # - self.activation_derivative: the derivative of the activation function\n",
    "        # - self.input: the input of the layer\n",
    "        # - np.multiply: the element-wise multiplication of the output_gradient and the activation_derivative\n",
    "        # - return: the gradient of the input of the layer\n",
    "        return np.multiply(output_gradient, self.activation_derivative(self.input))\n",
    "    \n",
    "class Sigmoid(Activation):\n",
    "    def __init__(self):\n",
    "        def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "            \"\"\"\n",
    "            Calculate the sigmoid of a given input.\n",
    "            \"\"\"\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        def sigmoid_derivative(x: np.ndarray) -> np.ndarray:\n",
    "            \"\"\"\n",
    "            Calculate the derivative of the sigmoid of a given input.\n",
    "            \"\"\"\n",
    "            return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "        # Call the parent class constructor to initialize the activation and activation_derivative\n",
    "        super().__init__(sigmoid, sigmoid_derivative)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcabca37",
   "metadata": {},
   "source": [
    "# 8. Apply CNN to MNIST\n",
    "Now let's train our **convolutional neural network** over the popular MNIST database. Our goal would be to classify `0` and `1` handwritten images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1e302d",
   "metadata": {},
   "source": [
    "#### 8.1 Download and unpack data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b37f2efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Reading the csv files...\n",
      "4. Unpacking the data...\n",
      "\tX_train: (60000, 28, 28), X_test: (10000, 28, 28), Y_train: (60000,), Y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Create `data` folder, if it does not exist.\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "\n",
    "# STEP 2: Load the data from the server, unless the file exists.\n",
    "if not os.path.isfile(\"data/mnist.zip\"):\n",
    "    print(\"1. Downloading the mnist.zip file...\")\n",
    "    response = requests.get(\"https://www.kaggle.com/api/v1/datasets/download/oddrationale/mnist-in-csv\")\n",
    "    with open(\"data/mnist.zip\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# STEP 3: Unpack the `mnist.zip` file, if it is not already unpacked.\n",
    "if not os.path.isfile(\"data/mnist/mnist_train.csv\"):\n",
    "    print(\"2. Unpacking the `mnist.zip` file...\")\n",
    "    with zipfile.ZipFile('data/mnist.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('data/mnist')\n",
    "\n",
    "# STEP 4: Read the csv files.\n",
    "print(\"3. Reading the csv files...\")\n",
    "X_train = np.loadtxt(\"data/mnist/mnist_train.csv\", delimiter=\",\", skiprows=1, dtype=np.uint8)\n",
    "X_test = np.loadtxt(\"data/mnist/mnist_test.csv\", delimiter=\",\", skiprows=1, dtype=np.uint8)\n",
    "\n",
    "# STEP 5: Unpack the data.\n",
    "print(\"4. Unpacking the data...\")\n",
    "# Extract the first column as the label.\n",
    "Y_train, Y_test = X_train[:, 0], X_test[:, 0]\n",
    "X_train, X_test = X_train[:, 1:], X_test[:, 1:]\n",
    "# Reshape from (60000, 784) to (60000, 28, 28)\n",
    "X_train = X_train.reshape(-1, 28, 28)\n",
    "X_test = X_test.reshape(-1, 28, 28)\n",
    "print(f\"\\tX_train: {X_train.shape}, X_test: {X_test.shape}, Y_train: {Y_train.shape}, Y_test: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23534cae",
   "metadata": {},
   "source": [
    "#### 8.2 Preprocess the data\n",
    "\n",
    "Basic preprocessing is needed:\n",
    "* reshape from $(28, 28)$ to $(1, 28, 28)$ where $1$ is basically the depth (channels) of the image\n",
    "* normalize values from $[0, 255]$ to $[0, 1]$\n",
    "* **one-hot encode** the labels (the $Y$-values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64a1ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Preprocessing the data...\n",
      "\tX_train_processed: (1000, 1, 28, 28), Y_train_processed: (1000, 2, 1)\n",
      "\tX_test_processed: (1000, 1, 28, 28), Y_test_processed: (1000, 2, 1)\n",
      "6. Displaying the first and second images on one plot...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def one_hot_encode(Y: np.ndarray, num_classes: int):\n",
    "    \"\"\"\n",
    "    Encode output (a number in [0,9]) into a vector of size 10 (e.g. 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "    Args:\n",
    "        Y: np.ndarray (e.g. with shape (60000,))\n",
    "\n",
    "    Returns:\n",
    "        Y_encoded: np.ndarray (e.g. with shape (60000, 10))\n",
    "    \"\"\"\n",
    "    # Initialize a matrix of zeros with shape (len(Y), num_classes - e.g. (1000, 2))\n",
    "    Y_encoded = np.zeros((Y.shape[0], num_classes))\n",
    "    # For each row, set the corresponding column (feature) to 1 (e.g. [0, 1] for 1 and [1, 0] for 0)\n",
    "    for i in range(Y.shape[0]):\n",
    "        Y_encoded[i, Y[i]] = 1\n",
    "    # Return the encoded matrix\n",
    "    return Y_encoded\n",
    "\n",
    "def preprocess_data(X: np.ndarray, Y: np.ndarray, limit: int):\n",
    "    \"\"\"\n",
    "    Preprocess data for training a convolutional neural network.\n",
    "\n",
    "    Args:\n",
    "        X: np.ndarray (e.g. with shape (1000, 28, 28))\n",
    "        Y: np.ndarray (e.g. with shape (1000,))\n",
    "        limit: int\n",
    "\n",
    "    Returns:\n",
    "        X: np.ndarray (e.g. with shape (1000, 28 * 28, 1))\n",
    "        Y: np.ndarray (e.g. with shape (1000, 10, 1))\n",
    "    \"\"\"\n",
    "    # Limit only to 0 and 1 images.\n",
    "    zero_index = np.where(Y == 0)[0][:limit]\n",
    "    one_index = np.where(Y == 1)[0][:limit]\n",
    "    all_indices = np.concatenate((zero_index, one_index))\n",
    "    X, Y = X[all_indices], Y[all_indices]\n",
    "    # Reshape from (1000, 28, 28) to (1000, 1, 28, 28) since the CNN expects the depth to be the first dimension\n",
    "    X = X.reshape(len(X), 1, 28, 28)\n",
    "    # Normalize [0, 255] to [0, 1]\n",
    "    X = X.astype(\"float32\") / 255\n",
    "    # Encode output (a number in [0,9]) into a vector of size 10 (e.g. 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
    "    Y = one_hot_encode(Y, 2)\n",
    "    # Reshape from (1000, 2) to (1000, 2, 1) - i.e. to be a column vector, since this is what the dense layer expects as input\n",
    "    Y = Y.reshape(len(Y), 2, 1)\n",
    "    return X, Y\n",
    "\n",
    "print(\"5. Preprocessing the data...\")\n",
    "X_train_processed, Y_train_processed = preprocess_data(X_train, Y_train, 500)\n",
    "X_test_processed, Y_test_processed = preprocess_data(X_test, Y_test, 500)\n",
    "print(f\"\\tX_train_processed: {X_train_processed.shape}, Y_train_processed: {Y_train_processed.shape}\")\n",
    "print(f\"\\tX_test_processed: {X_test_processed.shape}, Y_test_processed: {Y_test_processed.shape}\")\n",
    "\n",
    "# Display the two random images\n",
    "print(\"6. Displaying the first and second images on one plot...\")\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(X_train_processed[0, 0], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(X_train_processed[501, 0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2343f8b9",
   "metadata": {},
   "source": [
    "#### 8.3 Design a CNN\n",
    "\n",
    "Let's visually present the **architecture of the neural network** that we are going to build for classifying images (whether they contain a handwritten $0$ or $1$).\n",
    "\n",
    "<center><img src=\"img/cnn_example.png\" alt=\"The architecture of the CNN that we are going to build\" width=\"770\" height=\"450\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 15.</b> The architecture of the CNN that we are building</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bf5f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network\n",
    "network = [\n",
    "    Convolutional((1, 28, 28), 3, 5),       # Convolutional layer with 5 kernels of size 3x3\n",
    "    Sigmoid(),                              # We always use an activation function after a convolutional layer\n",
    "    Reshape((5, 26, 26), (5 * 26 * 26, 1)), # Reshape the output of the convolutional layer to a 2D array\n",
    "    Dense(5 * 26 * 26, 2),                  # Dense layer with 2 output neurons (0 or 1)\n",
    "    Sigmoid()                               # We always use an activation function after a dense layer\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4d041",
   "metadata": {},
   "source": [
    "#### 8.4 Train the network\n",
    "Finally, let's fit the model with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d34d7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(network, input):\n",
    "    output = input\n",
    "    for layer in network:\n",
    "        output = layer.forward(output)\n",
    "    return output\n",
    "\n",
    "def train(network, loss, loss_prime, x_train, y_train, epochs = 1000, learning_rate = 0.01, verbose = True):\n",
    "    error_history = []\n",
    "    for e in range(epochs):\n",
    "        error = 0\n",
    "        for x, y in zip(x_train, y_train):\n",
    "            # forward\n",
    "            output = predict(network, x)\n",
    "\n",
    "            # error\n",
    "            error += loss(y, output)\n",
    "\n",
    "            # backward\n",
    "            grad = loss_prime(y, output)\n",
    "            for layer in reversed(network):\n",
    "                grad = layer.backward(grad, learning_rate)\n",
    "\n",
    "        error /= len(x_train)\n",
    "        error_history.append(error)\n",
    "        if verbose:\n",
    "            print(f\"{e + 1}/{epochs}, error={error}\")\n",
    "    return error_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9201690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/30, error=0.16978142237234053\n",
      "2/30, error=0.15512490220522826\n",
      "3/30, error=0.06424561578936121\n",
      "4/30, error=0.040971938826523606\n",
      "5/30, error=0.030889468187522008\n",
      "6/30, error=0.025251206924264163\n",
      "7/30, error=0.022623474827516026\n",
      "8/30, error=0.02272939027127823\n",
      "9/30, error=0.01952250660407339\n",
      "10/30, error=0.016694577654486835\n",
      "11/30, error=0.014277212474680665\n",
      "12/30, error=0.01260373804871255\n",
      "13/30, error=0.011433218161141642\n",
      "14/30, error=0.010434529405148114\n",
      "15/30, error=0.009441978605167316\n",
      "16/30, error=0.00854302596940713\n",
      "17/30, error=0.007914800689965744\n",
      "18/30, error=0.007561607929809444\n",
      "19/30, error=0.007139323104791876\n",
      "20/30, error=0.006746249651590322\n",
      "21/30, error=0.006599863175421962\n",
      "22/30, error=0.0064374282278819046\n",
      "23/30, error=0.006301182172127619\n",
      "24/30, error=0.006193096912624796\n",
      "25/30, error=0.006074397197830517\n",
      "26/30, error=0.005959381376965277\n",
      "27/30, error=0.005851709126733602\n",
      "28/30, error=0.005768379449550135\n",
      "29/30, error=0.005696056049926934\n",
      "30/30, error=0.005618157322198274\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train\n",
    "loss_history = train(\n",
    "    network,\n",
    "    cross_entropy_loss,\n",
    "    cross_entropy_loss_derivative,\n",
    "    X_train_processed,\n",
    "    Y_train_processed,\n",
    "    epochs=30,\n",
    "    learning_rate=0.015\n",
    ")\n",
    "\n",
    "# Plot the loss history\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "568771d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.7%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test\n",
    "predictions = []\n",
    "actuals = []\n",
    "for x, y in zip(X_test_processed, Y_test_processed):\n",
    "    output = predict(network, x)\n",
    "    # Convert output vector to a scalar value of 0 or 1\n",
    "    predictions.append(np.argmax(output))\n",
    "    actuals.append(np.argmax(y))\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "true_positives = sum(1 for p, y in zip(predictions, actuals) if p == 1 and y == 1)\n",
    "true_negatives = sum(1 for p, y in zip(predictions, actuals) if p == 0 and y == 0)\n",
    "false_positives = sum(1 for p, y in zip(predictions, actuals) if p == 1 and y == 0)\n",
    "false_negatives = sum(1 for p, y in zip(predictions, actuals) if p == 0 and y == 1)\n",
    "confusion_matrix = np.array([[true_positives, false_positives], [false_negatives, true_negatives]])\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {(true_positives + true_negatives)*100 / len(X_test_processed)}%\")\n",
    "plt.matshow(confusion_matrix, cmap=\"Greens\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.xticks([0, 1], [0, 1], position=(0, -0.1))\n",
    "for (x, y), value in np.ndenumerate(confusion_matrix):\n",
    "    plt.text(x, y, f\"{value:.2f}\", va=\"center\", ha=\"center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f07d6",
   "metadata": {},
   "source": [
    " * **NB**: The **random weight generation** at the beginning could harm the training results. Sometimes the starting point leads to a suboptimal **local bottom** and the model can't get out of it with current implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
