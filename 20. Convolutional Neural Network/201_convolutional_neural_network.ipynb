{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c19b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7e3f17",
   "metadata": {},
   "source": [
    "# 1. Convolution\n",
    "#### 1.1 What is a convolution?\n",
    "\n",
    "Say I give you the coefficients of polynomials $P$ and $Q$. If I give you $x$, there are two ways to evaluate $P(x)*Q(x)$ :\n",
    "\n",
    "1. Evaluate $P(x)$ and $Q(x)$, and multiply them together; or\n",
    "2. Expand $PQ$ into a bigger polynomial, then evaluate it at $x$.\n",
    "\n",
    "In the first case, what you do to $P(x)$ and $Q(x)$ is called **multiplication**. In the second case, what you do to the coefficients of $P$ and $Q$ to get the coefficients of $PQ$ is called (discrete) **convolution**.\n",
    "\n",
    "As we have seen, multiplication and convolution can often be used to get the same results through different methods.\n",
    "\n",
    "\n",
    "* $ P(x) = 7 - 2x + 4x^2 $\n",
    "* $ Q(x) = 3 + x - 2x^2 $\n",
    "* $ x = 1 $\n",
    "\n",
    "1. **Approach 1**: \n",
    "$$(7 - 2 + 4).(3 + 1 - 2) = $$\n",
    "$$= 9 . 2 $$\n",
    "$$ = 18$$\n",
    "1. **Approach 2**: \n",
    "$$(7 - 2x + 4x^2).(3 + x - 2x^2) = $$\n",
    "$$ = (21) + (7x-6x) + (-14x^2 + 12x^2 - 2x^2) + (4x^3 + 4x^3) + (-8x^4) $$\n",
    "$$ = (21) + (x) + (-4x^2) + (8x^3) + (-8x^4) $$\n",
    "$$ = 18$$\n",
    "\n",
    "#### 1.2 Weighted average of a function\n",
    "In calculating a simple average all numbers are treated equally and assigned equal weight. But a weighted average assigns weights that determine in advance the relative importance of each data point. In calculating a **weighted average**, each number in the data set is multiplied by a predetermined weight before the final calculation is made.\n",
    "\n",
    "| Data point | Value | Weight | Weighted value |\n",
    "| --- | --- | --- | --- |\n",
    "| 1 | 10 | 2 | 20 |\n",
    "| 1 | 50 | 5 | 250 |\n",
    "| 1 | 40 | 3 | 120 |\n",
    "| **TOTAL** | 100 | 10 | 390 |\n",
    "| **Weighted Avg** |  |  | 39 |\n",
    "\n",
    "#### 1.3 Convolution - second explanation\n",
    "Given two weighted dice with following probability distribution:\n",
    "\n",
    "<center><img src=\"img/convolution_0.png\" alt=\"Two weighted dices\" width=\"800\" height=\"424\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 1.</b> Two unfair (weighted) dice </i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "Convolution would be applying one of the function over the other and getting as a result a new function with new probability distribution.\n",
    "<center><img src=\"img/convolution_1.png\" alt=\"Convolution of probability functions\" width=\"800\" height=\"191\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 2.</b> Convolution of probability functions </i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "In order to get the polynomial of the new function, the easiest would be to **FLIP** the second distribution (kernel).\n",
    "<center><img src=\"img/convolution_2.png\" alt=\"Flip the kernel\" width=\"400\" height=\"508\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 3.</b> Flip the second distribution (kernel) </i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "And now we can easily calculate each probability of the new function by executing a **dot product** between the respective terms and then slide the kernel to the right.\n",
    "<center><img src=\"img/convolution_3.png\" alt=\"Multiply and slide\" width=\"800\" height=\"423\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 4.</b> Multiply and slide right </i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "So, we end up with next formula.\n",
    "<center><img src=\"img/convolution_4.png\" alt=\"Convolution formula\" width=\"800\" height=\"436\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 5.</b> Convolution formula</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339d8604",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.4 Formula\n",
    "* The **discrete** formula looks like this:\n",
    "```\n",
    "y[n] = Σ x[k] * h[n - k]\n",
    "```\n",
    "or more formally:\n",
    "$$[f*g](s) = \\sum f(x) \\cdot g(s-x) $$\n",
    "\n",
    "Considering the general rule of thumb:\n",
    "$$\\sum \\text{... } \\rightarrow \\int \\text{... }dx$$\n",
    "\n",
    "* The **continious** formula would be:\n",
    "\n",
    "$$[f*g](s) = \\int_{-\\infty}^{\\infty} f(x) \\cdot g(s-x) dx$$\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "It’s easiest if you assume one of the functions is a probability density function $P$ centered at the origin. Then the convolution of $P$ with a function $Q$ at each $x$ is the weighted average of $Q$, using $P$ as the weight function centered at $x$. This clearly creates a **smooth approximation** of $Q$ where the random noise in $Q$ is averaged out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d43bfb7",
   "metadata": {},
   "source": [
    "# 2. Convolution operation\n",
    "\n",
    "Convolution between two matrices is a simple operation. You simply need to multiply the `input` matrix to a smaller `kernel` matrix in a specific way.\n",
    "\n",
    "\n",
    "But before that, you need to **flip** the kernel (i.e. reflect its content across the center).\n",
    "\n",
    "* NB: If not flipped, then we are not doing a **convolution**, but a **cross-correlation**.\n",
    "\n",
    "<center><img src=\"img/cnn_0.png\" alt=\"Convolution between two matrices\" width=\"600\" height=\"262\" /></center>\n",
    "<center><img src=\"img/cnn_1.png\" alt=\"Convolution between two matrices\" width=\"600\" height=\"259\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 6.</b> Convolution between two matrices</i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "We start from the upper-left corner of the `input` matrix. And we multiply each cell from the `input` to the corresponding cell into the `kernel` matrix. And we sum the result. This way we calculate the first cell of the `output` matrix.\n",
    "<center><img src=\"img/cnn_2.png\" alt=\"Multiply a submatrix from the `input` to the `kernel`\" width=\"600\" height=\"372\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 7.</b> Multiply a submatrix from the `input` to the `kernel`</i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "Then we slide the window to the right and calculate the next `output` cell.\n",
    "<center><img src=\"img/cnn_3.png\" alt=\"Slide the calculation window to the right\" width=\"600\" height=\"362\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 8.</b> Slide the calculation window to the right</i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "Once we can't slide more to the right, we go one row down and start over from the leftest cell.\n",
    "<center><img src=\"img/cnn_4.png\" alt=\"One row down and start again from the leftest cell\" width=\"600\" height=\"371\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 9.</b> One row down and start again from the leftest cell</i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "* **Size of the output**\n",
    "\n",
    "The size of the output matrix is calculated as:\n",
    "$$ O = I - K + 1 $$\n",
    "where $I$ is the size of the `input` matrix and $K$ is the size of the `kernel` matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c217bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate2d(image: np.ndarray, kernel: np.ndarray, mode: str = 'valid') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the correlation of the image with the kernel.\n",
    "    The correlation is a measure of how similar two signals are.\n",
    "    In the context of image processing, the correlation is used to find the features in the image.\n",
    "    The correlation is calculated by multiplying the kernel with the image cell by cell and summing the result.\n",
    "    The output is a matrix of the same size as the image.\n",
    "    The mode parameter determines the shape of the output matrix.\n",
    "    - 'full' mode: the output matrix is the same size as the image.\n",
    "    - 'valid' mode: the output matrix is the same size as the image minus the kernel size.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The input image.\n",
    "        kernel (np.ndarray): The kernel.\n",
    "        mode (str): The mode of the correlation.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The output matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the shape of the kernel and image\n",
    "    m, n = kernel.shape\n",
    "    y, x = image.shape\n",
    "\n",
    "    # CASE 1: Full mode - output shape is (y + m - 1, x + n - 1)\n",
    "    if mode == 'valid':\n",
    "        # SLOW IMPLEMENTATION (not vectorized)\n",
    "        # for i in range(y - m + 1):\n",
    "        #     for j in range(x - n + 1):\n",
    "        #         output[i, j] = (image[i:i+m, j:j+n] * kernel).sum()\n",
    "\n",
    "        # FAST IMPLEMENTATION (vectorized)\n",
    "        output = einsum_submatrices(image, kernel, x-n+1, y-m+1, m, n)\n",
    "    \n",
    "    # CASE 2: Valid mode - output shape is (y - m + 1, x - n + 1)\n",
    "    elif mode == 'full':\n",
    "        # Add padding to the input image\n",
    "        image = np.pad(image, ((m-1, m-1), (n-1, n-1)), mode='constant', constant_values=0)\n",
    "        output = einsum_submatrices(image, kernel, x+n-1, y+m-1, m, n)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid mode: {mode}\")\n",
    "    return output\n",
    "\n",
    "def einsum_submatrices(image: np.ndarray, kernel: np.ndarray, width: int, height: int, m: int, n: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate submatrices of the image in order to use np.einsum.\n",
    "    The submatrices are generated by sliding the kernel over the image.\n",
    "    The submatrices are then multiplied with the kernel and the result is summed.\n",
    "    The result is a matrix of the same size as the image.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The input image.\n",
    "        kernel (np.ndarray): The kernel.\n",
    "        width (int): The width of the output matrix.\n",
    "        height (int): The height of the output matrix.\n",
    "        m (int): The number of rows of the kernel.\n",
    "        n (int): The number of columns of the kernel.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    submatrices = []\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            submatrices.append(image[i:i+m, j:j+n])\n",
    "    submatrices = np.array(submatrices)\n",
    "    submatrices = submatrices.reshape(height, width, m, n)\n",
    "    # Multiply the submatrices with the kernel\n",
    "    # np.einsum is a function that allows you to perform a dot product between two arrays.\n",
    "    # It is a more efficient way to perform the dot product than using a for loop.\n",
    "    # It is also more readable and concise.\n",
    "    # Generate submatrices of the image in order to use np.einsum\n",
    "    return np.einsum('ijkl,kl->ij', submatrices, kernel)\n",
    "\n",
    "def convolve2d(image: np.ndarray, kernel: np.ndarray, mode: str = 'valid') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convolve the image with the kernel.\n",
    "    \"\"\"\n",
    "    # Flip the kernel\n",
    "    kernel = np.flip(kernel)\n",
    "    return correlate2d(image, kernel, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328ddd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4 -4]\n",
      " [-4 -4]]\n",
      "[[4 4]\n",
      " [4 4]]\n",
      "\n",
      "[[-1 -2 -3  0]\n",
      " [-4 -4 -4  3]\n",
      " [-7 -4 -4  6]\n",
      " [ 0  7  8  9]]\n",
      "[[ 1  2  3  0]\n",
      " [ 4  4  4 -3]\n",
      " [ 7  4  4 -6]\n",
      " [ 0 -7 -8 -9]]\n"
     ]
    }
   ],
   "source": [
    "test_input = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "# Kernel (filter)\n",
    "test_kernel = np.array([\n",
    "    [1, 0],\n",
    "    [0, -1]\n",
    "])\n",
    "\n",
    "print(correlate2d(test_input, test_kernel, mode='valid'))\n",
    "print(convolve2d(test_input, test_kernel, mode='valid'))\n",
    "print('')\n",
    "print(correlate2d(test_input, test_kernel, mode='full'))\n",
    "print(convolve2d(test_input, test_kernel, mode='full'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d10673",
   "metadata": {},
   "source": [
    "# 3. Convolutional Neural Network\n",
    "\n",
    "#### 3.1 Convolutional layer\n",
    "\n",
    "* **The input** is a 3-dimensional block of data (e.g. image tensor). In this case the depth is 3.\n",
    "* **The weights** are organized as kernels (a 3-dimensional block with the same depth as the input). The layer may have one or multiple kernels.\n",
    "* **The bias matrices** have the same shape as the outputs. The number of biases is equal to the number of kernels in the layer.\n",
    "* **The output** is a 3-dimensional block of data. The depth of the output is the same as the number of kernels.\n",
    "\n",
    "<center><img src=\"img/cnn_5.png\" alt=\"Convolutional layer with 2 kernels\" width=\"800\" height=\"404\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 10.</b> Convolutional layer with 2 kernels</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86746bcd",
   "metadata": {},
   "source": [
    "First, let's create an abstract class, which will further be used for any kind of layers in our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a83db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        # TODO: return output\n",
    "        pass\n",
    "\n",
    "    def backward(self, output_gradient: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        # TODO: update parameters and return input gradient\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d7828",
   "metadata": {},
   "source": [
    "Now, let's create the **convolutional layer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b4993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, kernel_size: int, num_of_kernels: int):\n",
    "        \"\"\"\n",
    "        Initialize the convolutional layer.\n",
    "        The layer will be initialized with random weights and biases.\n",
    "\n",
    "        The shape of the output is calculated as:\n",
    "         * output_shape = (num_of_kernels, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
    "         * kernel_shape = (num_of_kernels, input_depth, kernel_size, kernel_size)\n",
    "         * biases_shape = (output_shape)\n",
    "\n",
    "        Args:\n",
    "            input_shape: tuple, shape of the input data (depth, height, width)\n",
    "            kernel_size: int, size of the kernel (e.g. 4 for 4x4 kernel)\n",
    "            num_of_kernels: int, number of kernels in the layer (e.g. 2 for 2 kernels)\n",
    "        \"\"\"\n",
    "        input_depth, input_height, input_width = input_shape                            # (e.g. 3, 28, 28)\n",
    "        self.num_of_kernels = num_of_kernels                                            # (e.g. 2)\n",
    "        self.input_shape = input_shape                                                  # (e.g. 3, 28, 28)\n",
    "        self.kernel_shape = (num_of_kernels, input_depth, kernel_size, kernel_size)     # (e.g. 2, 3, 4, 4)\n",
    "        self.output_shape = (num_of_kernels, input_height - kernel_size + 1, input_width - kernel_size + 1) # (e.g. 2, 25, 25)\n",
    "\n",
    "        # Generate random weights and biases\n",
    "        self.kernels = np.random.randn(*self.kernel_shape)  # (e.g. 2, 3, 4, 4)\n",
    "        self.biases = np.random.randn(*self.output_shape)   # (e.g. 2, 25, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d7d1d",
   "metadata": {},
   "source": [
    "#### 3.2 Forward propagation\n",
    "**How the output is produced?**\n",
    "\n",
    "Take each matrix in the first kernel and compute the cross-correlation with the input data. Sum the three results and add up the first bias. This will produce the first output.\n",
    "\n",
    "\n",
    "<center><img src=\"img/cnn_6.png\" alt=\"Convolutional layer - how the output is produced\" width=\"800\" height=\"467\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 11.</b> Convolutional layer - how the output is produced</i></p>\n",
    "\n",
    "After that go on in the same manner for the next cells in this output matrix.\n",
    "\n",
    "\n",
    "Likewise, the second output is calculated by cross-correlating the input with the second kernel and second bias.\n",
    "\n",
    "\n",
    "<center><img src=\"img/cnn_7.png\" alt=\"Convolutional layer - the second output is produced in the same way, but using the second kernel\" width=\"800\" height=\"468\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 12.</b> Convolutional layer - the second output is produced in the same way, but using the second kernel</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47243107",
   "metadata": {},
   "source": [
    "We can simplify the formula to:\n",
    "$$Y_1 = B_1 + X_1 \\star K_{11} + X_2 \\star K_{12} + X_3 \\star K_{13} $$\n",
    "$$Y_2 = B_2 + X_2 \\star K_{21} + X_2 \\star K_{22} + X_3 \\star K_{23} $$\n",
    "$$ \\vdots $$\n",
    "$$Y_d = B_d + X_1 \\star K_{d1} + X_2 \\star K_{d2} + X_3 \\star K_{d3} $$\n",
    "\n",
    "Where $d$ is the the number of kernels (hence the depth of the outputs).\n",
    "\n",
    "\n",
    "\n",
    "<center><img src=\"img/cnn_8.png\" alt=\"Convolutional layer - the output formula (simplified)\" width=\"400\" height=\"227\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 13.</b> Convolutional layer - the output formula (simplified)</i></p>\n",
    "\n",
    "And if we generalize the shape of the input, we come up with following formula:\n",
    "\n",
    "$$Y_d = B_d + X_1 \\star K_{d1} + X_2 \\star K_{d2} + \\dots + X_n \\star K_{dn} $$\n",
    "\n",
    "or\n",
    "\n",
    "$$ Y_i = B_i + \\sum_{j=1}^{n}{X_j \\star K_{ij}} \\text{  ,  } i = 1 \\dots d$$\n",
    "\n",
    "Where $n$ is the depth of the input and $d$ is the number of kernels.\n",
    "\n",
    "\n",
    "If we go further, we will see a similarity between a regular dense layer and a convolutional layer. The only difference is that in the dense layer we calculate **dot product** between **matrices of scalar values**, while here we calculate **cross-correlated dot product** between **matrices of matrices**. But in general the dense layer is a subtype of the convolutional layer.\n",
    "\n",
    "<center><img src=\"img/cnn_9.png\" alt=\"Convolutional layer looks the same as a dense layer\" width=\"800\" height=\"288\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 14.</b> Convolutional layer looks very similar to a regular dense layer</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76ea1763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Forward pass through the convolutional layer.\n",
    "        - The input is a 3D tensor (e.g. image tensor).\n",
    "        - The output is a 3D tensor (e.g. feature map).\n",
    "\n",
    "    The formula is:\n",
    "        - Y_i = B_i + \\\\sum_{j=1}^{n}{X_j \\\\star K_{ij}}\n",
    "    where:\n",
    "        - Y_i is the output of the i-th kernel\n",
    "        - B_i is the bias of the i-th kernel\n",
    "        - X_j is the j-th depth of the input\n",
    "        - K_{ij} is the j-th depth of the i-th kernel\n",
    "        - n is the number of depths of the input\n",
    "\n",
    "    Args:\n",
    "        input: np.ndarray, input tensor (e.g. image tensor)\n",
    "    Returns:\n",
    "        np.ndarray, output tensor (e.g. feature map)\n",
    "    \"\"\"\n",
    "    self.input = input\n",
    "    self.output = np.copy(self.biases)\n",
    "\n",
    "    # For each kernel (e.g. 2)\n",
    "    for i in range(self.number_of_kernels): \n",
    "        # For each depth of the input (e.g. 3)\n",
    "        for j in range(self.input_shape[0]):\n",
    "            # The formula is:\n",
    "            # - output[i] += input[j] * kernels[i, j]\n",
    "            # where:\n",
    "            # - output[i] is the output of the i-th kernel\n",
    "            # - input[j] is the j-th depth of the input\n",
    "            # - kernels[i, j] is the j-th depth of the i-th kernel\n",
    "            # - mode='valid' is the mode of the correlation operation\n",
    "            self.output[i] += correlate2d(self.input[j], self.kernels[i, j], mode='valid')\n",
    "\n",
    "    # Return the output of the layer\n",
    "    return self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961a8c9",
   "metadata": {},
   "source": [
    "#### 3.3 Backward propagation\n",
    "\n",
    "We need to calculate the following derivatives:\n",
    "$$\\frac{dJ}{dK_{ij}}, \\frac{dJ}{dB_i}, \\frac{dJ}{dX_j} $$\n",
    "\n",
    "And after applying several *chain rules* and some math mojo we come up with next formulas:\n",
    "$$\\frac{dJ}{dK_{ij}} = X_j \\star \\frac{dJ}{dY_{i}}$$\n",
    "$$\\frac{dJ}{dB_i} = \\frac{dJ}{dY_{i}}$$\n",
    "$$\\frac{dJ}{dX_j} = \\sum_{i=1}^d {\\frac{dJ}{dY_{i}} \\ast_{full} }K $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63c4662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, output_gradient: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Backward pass through the convolutional layer.\n",
    "\n",
    "    Args:\n",
    "        output_gradient: np.ndarray, the gradient of the output (e.g. [[1, 2, 3], [4, 5, 6]])\n",
    "        learning_rate: float, the learning rate\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray, the gradient of the input (e.g. [1, 2, 3, 4, 5, 6])\n",
    "    \"\"\"\n",
    "    kernels_gradient = np.zeros(self.kernel_shape)\n",
    "    input_gradient = np.zeros(self.input_shape)\n",
    "\n",
    "    for i in range(self.num_of_kernels):\n",
    "        for j in range(self.input_shape[0]): # input depth\n",
    "            kernels_gradient[i, j] = correlate2d(self.input[j], output_gradient[i], mode='valid')\n",
    "            input_gradient[j] += convolve2d(output_gradient[i], self.kernels[i, j], mode='full')\n",
    "\n",
    "    self.kernels -= learning_rate * kernels_gradient\n",
    "    self.biases -= learning_rate * output_gradient\n",
    "\n",
    "    return input_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c4790b",
   "metadata": {},
   "source": [
    "So, finally, the class will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d63ed094",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, kernel_size: int, num_of_kernels: int):\n",
    "        \"\"\"\n",
    "        Initialize the convolutional layer.\n",
    "        The layer will be initialized with random weights and biases.\n",
    "\n",
    "        The shape of the output is calculated as:\n",
    "         * output_shape = (num_of_kernels, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
    "         * kernel_shape = (num_of_kernels, input_depth, kernel_size, kernel_size)\n",
    "         * biases_shape = (output_shape)\n",
    "\n",
    "        Args:\n",
    "            input_shape: tuple, shape of the input data (depth, height, width)\n",
    "            kernel_size: int, size of the kernel (e.g. 4 for 4x4 kernel)\n",
    "            num_of_kernels: int, number of kernels in the layer (e.g. 2 for 2 kernels)\n",
    "        \"\"\"\n",
    "        input_depth, input_height, input_width = input_shape                            # (e.g. 3, 28, 28)\n",
    "        self.num_of_kernels = num_of_kernels                                            # (e.g. 2)\n",
    "        self.input_shape = input_shape                                                  # (e.g. 3, 28, 28)\n",
    "        self.kernel_shape = (num_of_kernels, input_depth, kernel_size, kernel_size)     # (e.g. 2, 3, 4, 4)\n",
    "        self.output_shape = (num_of_kernels, input_height - kernel_size + 1, input_width - kernel_size + 1) # (e.g. 2, 25, 25)\n",
    "\n",
    "        # Generate random weights and biases\n",
    "        self.kernels = np.random.randn(*self.kernel_shape)  # (e.g. 2, 3, 4, 4)\n",
    "        self.biases = np.random.randn(*self.output_shape)   # (e.g. 2, 25, 25)\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Forward pass through the convolutional layer.\n",
    "            - The input is a 3D tensor (e.g. image tensor).\n",
    "            - The output is a 3D tensor (e.g. feature map).\n",
    "\n",
    "        The formula is:\n",
    "            - Y_i = B_i + \\\\sum_{j=1}^{n}{X_j \\\\star K_{ij}}\n",
    "        where:\n",
    "            - Y_i is the output of the i-th kernel\n",
    "            - B_i is the bias of the i-th kernel\n",
    "            - X_j is the j-th depth of the input\n",
    "            - K_{ij} is the j-th depth of the i-th kernel\n",
    "            - n is the number of depths of the input\n",
    "\n",
    "        Args:\n",
    "            input: np.ndarray, input tensor (e.g. image tensor)\n",
    "        Returns:\n",
    "            np.ndarray, output tensor (e.g. feature map)\n",
    "        \"\"\"\n",
    "        self.input = input\n",
    "        self.output = np.copy(self.biases) # Output = bias + sum(input * kernel)\n",
    "\n",
    "        # For each kernel (e.g. 2)\n",
    "        for i in range(self.num_of_kernels): \n",
    "            # For each depth of the input (e.g. 3)\n",
    "            for j in range(self.input_shape[0]):\n",
    "                # The formula is:\n",
    "                # - output[i] += input[j] * kernels[i, j]\n",
    "                # where:\n",
    "                # - output[i] is the output of the i-th kernel\n",
    "                # - input[j] is the j-th depth of the input\n",
    "                # - kernels[i, j] is the j-th depth of the i-th kernel\n",
    "                # - mode='valid' is the mode of the correlation operation\n",
    "                self.output[i] += correlate2d(self.input[j], self.kernels[i, j], mode='valid')\n",
    "\n",
    "        # Return the output of the layer\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_gradient: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Backward pass through the convolutional layer.\n",
    "\n",
    "        Args:\n",
    "            output_gradient: np.ndarray, the gradient of the output (e.g. [[1, 2, 3], [4, 5, 6]])\n",
    "            learning_rate: float, the learning rate\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray, the gradient of the input (e.g. [1, 2, 3, 4, 5, 6])\n",
    "        \"\"\"\n",
    "        kernels_gradient = np.zeros(self.kernel_shape)\n",
    "        input_gradient = np.zeros(self.input_shape)\n",
    "\n",
    "        for i in range(self.num_of_kernels):\n",
    "            for j in range(self.input_shape[0]): # input depth\n",
    "                kernels_gradient[i, j] = correlate2d(self.input[j], output_gradient[i], mode='valid')\n",
    "                input_gradient[j] += convolve2d(output_gradient[i], self.kernels[i, j], mode='full')\n",
    "\n",
    "        self.kernels -= learning_rate * kernels_gradient\n",
    "        self.biases -= learning_rate * output_gradient\n",
    "\n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b8190c",
   "metadata": {},
   "source": [
    "# 4. Reshape Layer\n",
    "\n",
    "This layer is needed since the output of a **convolutional layer** is a 3D block. While typically at the end of a network we use **dense layers**, which take in a column vector as an input. Therefore, we need a mechanism that reshapes data, hence the **reshape layer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "071ac865",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, output_shape: tuple):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Reshape the input to the output shape.\n",
    "\n",
    "        Args:\n",
    "            input: np.ndarray, the input to be reshaped (e.g. [1, 2, 3, 4, 5, 6])\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray, the reshaped input (e.g. [[1, 2, 3], [4, 5, 6]])\n",
    "        \"\"\"\n",
    "        return input.reshape(self.output_shape)\n",
    "\n",
    "    def backward(self, output_gradient: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Reshape the output gradient to the input shape.\n",
    "\n",
    "        Args:\n",
    "            output_gradient: np.ndarray, the gradient of the output (e.g. [[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray, the gradient of the input (e.g. [1, 2, 3, 4, 5, 6])\n",
    "        \"\"\"\n",
    "        return output_gradient.reshape(self.input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e481d0c",
   "metadata": {},
   "source": [
    "# 5. Dense layer\n",
    "We will add a standart **dense** layer, which you should already know from all other neural networks, covered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ef1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(output_size, input_size)\n",
    "        self.bias = np.random.randn(output_size, 1)\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        self.input = input\n",
    "        # Return the standard output of the layer (weights * input + bias)\n",
    "        return np.dot(self.weights, self.input) + self.bias\n",
    "\n",
    "    def backward(self, output_gradient: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        # Calculate the weights gradient\n",
    "        weights_gradient = np.dot(output_gradient, self.input.T)\n",
    "        # Calculate the input gradient\n",
    "        input_gradient = np.dot(self.weights.T, output_gradient)\n",
    "        # Update the weights and bias\n",
    "        self.weights -= learning_rate * weights_gradient\n",
    "        self.bias -= learning_rate * output_gradient\n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a296a98",
   "metadata": {},
   "source": [
    "# 6. Cross Entropy Loss\n",
    "We'll prepare our **convolutional neural network** for classification task. Hence, we'll use the **cross entropy loss** formula.\n",
    "\n",
    "If this is the **actual** output of the network:\n",
    "$$ \\hat{Y} = \\begin{bmatrix}\\hat{y_1}\\\\\\hat{y_2}\\\\\\vdots\\\\\\hat{y_i}\\end{bmatrix}  ,  \\hat{y_i} \\in \\{0,1\\} $$\n",
    "\n",
    "And this is the **expected** one:\n",
    "$$ Y = \\begin{bmatrix}y_1\\\\y_2\\\\\\vdots\\\\y_i\\end{bmatrix} $$\n",
    "\n",
    "Then the **cross-entropy loss** formula would be:\n",
    "$$ J = -\\frac{1}{n} \\sum_{i=1}^{n} \\hat{y_i} log(y_i) + (1-\\hat{y_i}) log(1-y_i) $$\n",
    "\n",
    "Thus, the derivative of $J$ w.r.t to the **output** would be:\n",
    "$$ \\frac{dJ}{dY} = \\begin{bmatrix} \\frac{dJ}{dy_1} \\\\ \\frac{dJ}{dy_2} \\\\\\vdots\\\\ \\frac{dJ}{dy_i} \\end{bmatrix} \n",
    "= \\frac{1}{n} \\left(\\frac{1-\\hat{y_i}}{1-y_i} - \\frac{\\hat{y_i}}{y_i} \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9b1a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(Y_true: np.ndarray, Y_pred: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the cross-entropy loss.\n",
    "\n",
    "    Args:\n",
    "        Y_true: np.ndarray, the true labels (e.g. [0, 1, 0, 1, 0])\n",
    "        Y_pred: np.ndarray, the predicted labels (e.g. [0.1, 0.9, 0.1, 0.9, 0.1])\n",
    "\n",
    "    Returns:\n",
    "        float, the cross-entropy loss\n",
    "    \"\"\"\n",
    "    e = 1e-7 # Avoid log(0)\n",
    "    return -np.mean(Y_true * np.log(Y_pred + e) + (1 - Y_true) * np.log(1 - Y_pred + e))\n",
    "\n",
    "def cross_entropy_loss_derivative(Y_true: np.ndarray, Y_pred: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the derivative of the cross-entropy loss.\n",
    "\n",
    "    Args:\n",
    "        Y_true: np.ndarray, the true labels (e.g. [0, 1, 0, 1, 0])\n",
    "        Y_pred: np.ndarray, the predicted labels (e.g. [0.1, 0.9, 0.1, 0.9, 0.1])\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray, the derivative of the cross-entropy loss\n",
    "    \"\"\"\n",
    "    e = 1e-7 # Avoid division by zero\n",
    "    return ((1 - Y_true) / (1 - Y_pred + e) - Y_true / (Y_pred + e)) / np.size(Y_true) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a7df8a",
   "metadata": {},
   "source": [
    "# 7. Activation function\n",
    "In our case we would use a **sigmoid** function for activation. And let's pack it as a layer, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c5fc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation(Layer):\n",
    "    def __init__(self, activation, activation_derivative):\n",
    "        self.activation = activation\n",
    "        self.activation_derivative = activation_derivative\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        # Explanation:\n",
    "        # - self.input: the input of the layer\n",
    "        # - self.activation: the activation function\n",
    "        # - return: the output of the layer\n",
    "        return self.activation(self.input)\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        # Explanation:\n",
    "        # - output_gradient: the gradient of the output of the layer\n",
    "        # - self.activation_derivative: the derivative of the activation function\n",
    "        # - self.input: the input of the layer\n",
    "        # - np.multiply: the element-wise multiplication of the output_gradient and the activation_derivative\n",
    "        # - return: the gradient of the input of the layer\n",
    "        return np.multiply(output_gradient, self.activation_derivative(self.input))\n",
    "    \n",
    "class Sigmoid(Activation):\n",
    "    def __init__(self):\n",
    "        def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "            \"\"\"\n",
    "            Calculate the sigmoid of a given input.\n",
    "            \"\"\"\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        def sigmoid_derivative(x: np.ndarray) -> np.ndarray:\n",
    "            \"\"\"\n",
    "            Calculate the derivative of the sigmoid of a given input.\n",
    "            \"\"\"\n",
    "            return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "        # Call the parent class constructor to initialize the activation and activation_derivative\n",
    "        super().__init__(sigmoid, sigmoid_derivative)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcabca37",
   "metadata": {},
   "source": [
    "# 8. Apply CNN to MNIST\n",
    "Now let's train our **convolutional neural network** over the popular MNIST database. Our goal would be to classify `0` and `1` handwritten images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1e302d",
   "metadata": {},
   "source": [
    "#### 8.1 Download and unpack data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b37f2efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Reading the csv files...\n",
      "4. Unpacking the data...\n",
      "\tX_train: (60000, 28, 28), X_test: (10000, 28, 28), Y_train: (60000,), Y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Create `data` folder, if it does not exist.\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "\n",
    "# STEP 2: Load the data from the server, unless the file exists.\n",
    "if not os.path.isfile(\"data/mnist.zip\"):\n",
    "    print(\"1. Downloading the mnist.zip file...\")\n",
    "    response = requests.get(\"https://www.kaggle.com/api/v1/datasets/download/oddrationale/mnist-in-csv\")\n",
    "    with open(\"data/mnist.zip\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# STEP 3: Unpack the `mnist.zip` file, if it is not already unpacked.\n",
    "if not os.path.isfile(\"data/mnist/mnist_train.csv\"):\n",
    "    print(\"2. Unpacking the `mnist.zip` file...\")\n",
    "    with zipfile.ZipFile('data/mnist.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('data/mnist')\n",
    "\n",
    "# STEP 4: Read the csv files.\n",
    "print(\"3. Reading the csv files...\")\n",
    "X_train = np.loadtxt(\"data/mnist/mnist_train.csv\", delimiter=\",\", skiprows=1, dtype=np.uint8)\n",
    "X_test = np.loadtxt(\"data/mnist/mnist_test.csv\", delimiter=\",\", skiprows=1, dtype=np.uint8)\n",
    "\n",
    "# STEP 5: Unpack the data.\n",
    "print(\"4. Unpacking the data...\")\n",
    "# Extract the first column as the label.\n",
    "Y_train, Y_test = X_train[:, 0], X_test[:, 0]\n",
    "X_train, X_test = X_train[:, 1:], X_test[:, 1:]\n",
    "# Reshape from (60000, 784) to (60000, 28, 28)\n",
    "X_train = X_train.reshape(-1, 28, 28)\n",
    "X_test = X_test.reshape(-1, 28, 28)\n",
    "print(f\"\\tX_train: {X_train.shape}, X_test: {X_test.shape}, Y_train: {Y_train.shape}, Y_test: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23534cae",
   "metadata": {},
   "source": [
    "#### 8.2 Preprocess the data\n",
    "\n",
    "Basic preprocessing is needed:\n",
    "* reshape from $(28, 28)$ to $(1, 28, 28)$ where $1$ is basically the depth (channels) of the image\n",
    "* normalize values from $[0, 255]$ to $[0, 1]$\n",
    "* **one-hot encode** the labels (the $Y$-values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64a1ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Preprocessing the data...\n",
      "\tX_train_processed: (1000, 1, 28, 28), Y_train_processed: (1000, 2, 1)\n",
      "\tX_test_processed: (1000, 1, 28, 28), Y_test_processed: (1000, 2, 1)\n",
      "6. Displaying the first and second images on one plot...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def one_hot_encode(Y: np.ndarray, num_classes: int):\n",
    "    \"\"\"\n",
    "    Encode output (a number in [0,9]) into a vector of size 10 (e.g. 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "    Args:\n",
    "        Y: np.ndarray (e.g. with shape (60000,))\n",
    "\n",
    "    Returns:\n",
    "        Y_encoded: np.ndarray (e.g. with shape (60000, 10))\n",
    "    \"\"\"\n",
    "    # Initialize a matrix of zeros with shape (len(Y), num_classes - e.g. (1000, 2))\n",
    "    Y_encoded = np.zeros((Y.shape[0], num_classes))\n",
    "    # For each row, set the corresponding column (feature) to 1 (e.g. [0, 1] for 1 and [1, 0] for 0)\n",
    "    for i in range(Y.shape[0]):\n",
    "        Y_encoded[i, Y[i]] = 1\n",
    "    # Return the encoded matrix\n",
    "    return Y_encoded\n",
    "\n",
    "def preprocess_data(X: np.ndarray, Y: np.ndarray, limit: int):\n",
    "    \"\"\"\n",
    "    Preprocess data for training a convolutional neural network.\n",
    "\n",
    "    Args:\n",
    "        X: np.ndarray (e.g. with shape (1000, 28, 28))\n",
    "        Y: np.ndarray (e.g. with shape (1000,))\n",
    "        limit: int\n",
    "\n",
    "    Returns:\n",
    "        X: np.ndarray (e.g. with shape (1000, 28 * 28, 1))\n",
    "        Y: np.ndarray (e.g. with shape (1000, 10, 1))\n",
    "    \"\"\"\n",
    "    # Limit only to 0 and 1 images.\n",
    "    zero_index = np.where(Y == 0)[0][:limit]\n",
    "    one_index = np.where(Y == 1)[0][:limit]\n",
    "    all_indices = np.concatenate((zero_index, one_index))\n",
    "    X, Y = X[all_indices], Y[all_indices]\n",
    "    # Reshape from (1000, 28, 28) to (1000, 1, 28, 28) since the CNN expects the depth to be the first dimension\n",
    "    X = X.reshape(len(X), 1, 28, 28)\n",
    "    # Normalize [0, 255] to [0, 1]\n",
    "    X = X.astype(\"float32\") / 255\n",
    "    # Encode output (a number in [0,9]) into a vector of size 10 (e.g. 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
    "    Y = one_hot_encode(Y, 2)\n",
    "    # Reshape from (1000, 2) to (1000, 2, 1) - i.e. to be a column vector, since this is what the dense layer expects as input\n",
    "    Y = Y.reshape(len(Y), 2, 1)\n",
    "    return X, Y\n",
    "\n",
    "print(\"5. Preprocessing the data...\")\n",
    "X_train_processed, Y_train_processed = preprocess_data(X_train, Y_train, 500)\n",
    "X_test_processed, Y_test_processed = preprocess_data(X_test, Y_test, 500)\n",
    "print(f\"\\tX_train_processed: {X_train_processed.shape}, Y_train_processed: {Y_train_processed.shape}\")\n",
    "print(f\"\\tX_test_processed: {X_test_processed.shape}, Y_test_processed: {Y_test_processed.shape}\")\n",
    "\n",
    "# Display the two random images\n",
    "print(\"6. Displaying the first and second images on one plot...\")\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(X_train_processed[0, 0], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(X_train_processed[501, 0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4d041",
   "metadata": {},
   "source": [
    "#### 8.3 Train the network\n",
    "Finally, let's fit the model with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d34d7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(network, input):\n",
    "    output = input\n",
    "    for layer in network:\n",
    "        output = layer.forward(output)\n",
    "    return output\n",
    "\n",
    "def train(network, loss, loss_prime, x_train, y_train, epochs = 1000, learning_rate = 0.01, verbose = True):\n",
    "    error_history = []\n",
    "    for e in range(epochs):\n",
    "        error = 0\n",
    "        for x, y in zip(x_train, y_train):\n",
    "            # forward\n",
    "            output = predict(network, x)\n",
    "\n",
    "            # error\n",
    "            error += loss(y, output)\n",
    "\n",
    "            # backward\n",
    "            grad = loss_prime(y, output)\n",
    "            for layer in reversed(network):\n",
    "                grad = layer.backward(grad, learning_rate)\n",
    "\n",
    "        error /= len(x_train)\n",
    "        error_history.append(error)\n",
    "        if verbose:\n",
    "            print(f\"{e + 1}/{epochs}, error={error}\")\n",
    "    return error_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9201690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/30, error=0.17109687732560228\n",
      "2/30, error=0.07249213705387189\n",
      "3/30, error=0.034821861448376484\n",
      "4/30, error=0.024810560512826717\n",
      "5/30, error=0.02271346254487751\n",
      "6/30, error=0.019278218557854627\n",
      "7/30, error=0.016242969716168894\n",
      "8/30, error=0.014809906208818181\n",
      "9/30, error=0.013039432095321548\n",
      "10/30, error=0.011337152041304858\n",
      "11/30, error=0.010448577304688749\n",
      "12/30, error=0.00934437330794242\n",
      "13/30, error=0.008788636174113185\n",
      "14/30, error=0.008319218269479536\n",
      "15/30, error=0.007710835731059909\n",
      "16/30, error=0.006969342252154428\n",
      "17/30, error=0.006525644107633373\n",
      "18/30, error=0.006418658827540399\n",
      "19/30, error=0.006403519766422155\n",
      "20/30, error=0.006317367540591643\n",
      "21/30, error=0.006115043571153895\n",
      "22/30, error=0.005908616774944572\n",
      "23/30, error=0.005756491755756356\n",
      "24/30, error=0.00563283739012895\n",
      "25/30, error=0.005532721525075359\n",
      "26/30, error=0.005431278337502185\n",
      "27/30, error=0.005269837970315984\n",
      "28/30, error=0.005102151725862389\n",
      "29/30, error=0.004930374933808272\n",
      "30/30, error=0.004737686235903441\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# neural network\n",
    "network = [\n",
    "    Convolutional((1, 28, 28), 3, 5),       # Convolutional layer with 5 kernels of size 3x3\n",
    "    Sigmoid(),                              # We always use an activation function after a convolutional layer\n",
    "    Reshape((5, 26, 26), (5 * 26 * 26, 1)), # Reshape the output of the convolutional layer to a 2D array\n",
    "    Dense(5 * 26 * 26, 2),                  # Dense layer with 2 output neurons (0 or 1)\n",
    "    Sigmoid()                               # We always use an activation function after a dense layer\n",
    "]\n",
    "\n",
    "# train\n",
    "loss_history = train(\n",
    "    network,\n",
    "    cross_entropy_loss,\n",
    "    cross_entropy_loss_derivative,\n",
    "    X_train_processed,\n",
    "    Y_train_processed,\n",
    "    epochs=30,\n",
    "    learning_rate=0.015\n",
    ")\n",
    "\n",
    "# Plot the loss history\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "568771d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.2%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test\n",
    "predictions = []\n",
    "actuals = []\n",
    "for x, y in zip(X_test_processed, Y_test_processed):\n",
    "    output = predict(network, x)\n",
    "    # Convert output vector to a scalar value of 0 or 1\n",
    "    predictions.append(np.argmax(output))\n",
    "    actuals.append(np.argmax(y))\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "true_positives = sum(1 for p, y in zip(predictions, actuals) if p == 1 and y == 1)\n",
    "true_negatives = sum(1 for p, y in zip(predictions, actuals) if p == 0 and y == 0)\n",
    "false_positives = sum(1 for p, y in zip(predictions, actuals) if p == 1 and y == 0)\n",
    "false_negatives = sum(1 for p, y in zip(predictions, actuals) if p == 0 and y == 1)\n",
    "confusion_matrix = np.array([[true_positives, false_positives], [false_negatives, true_negatives]])\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {(true_positives + true_negatives)*100 / len(X_test_processed)}%\")\n",
    "plt.matshow(confusion_matrix, cmap=\"Greens\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.xticks([0, 1], [0, 1], position=(0, -0.1))\n",
    "for (x, y), value in np.ndenumerate(confusion_matrix):\n",
    "    plt.text(x, y, f\"{value:.2f}\", va=\"center\", ha=\"center\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
