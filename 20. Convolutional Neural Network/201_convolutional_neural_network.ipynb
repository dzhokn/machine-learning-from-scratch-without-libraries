{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52c19b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7e3f17",
   "metadata": {},
   "source": [
    "# 1. Convolution\n",
    "#### 1.1 What is a convolution?\n",
    "\n",
    "Say I give you the coefficients of polynomials $P$ and $Q$. If I give you $x$, there are two ways to evaluate $P(x)*Q(x)$ :\n",
    "\n",
    "1. Evaluate $P(x)$ and $Q(x)$, and multiply them together; or\n",
    "2. Expand $PQ$ into a bigger polynomial, then evaluate it at $x$.\n",
    "\n",
    "In the first case, what you do to $P(x)$ and $Q(x)$ is called **multiplication**. In the second case, what you do to the coefficients of $P$ and $Q$ to get the coefficients of $PQ$ is called (discrete) **convolution**.\n",
    "\n",
    "As we have seen, multiplication and convolution can often be used to get the same results through different methods.\n",
    "\n",
    "\n",
    "* $ P(x) = 7 - 2x + 4x^2 $\n",
    "* $ Q(x) = 3 + x - 2x^2 $\n",
    "* $ x = 1 $\n",
    "\n",
    "**Approach 1**: \n",
    "$$(7 - 2 + 4).(3 + 1 - 2) = $$\n",
    "$$= 9 . 2 $$\n",
    "$$ = 18$$\n",
    "**Approach 2**: \n",
    "$$(7 - 2x + 4x^2).(3 + x - 2x^2) = $$\n",
    "$$ = (21) + (7x-6x) + (-14x^2 + 12x^2 - 2x^2) + (4x^3 + 4x^3) + (-8x^4) $$\n",
    "$$ = (21) + (x) + (-4x^2) + (8x^3) + (-8x^4) $$\n",
    "$$ = 18$$\n",
    "\n",
    "#### 1.2 Weighted average of a function\n",
    "In calculating a simple average all numbers are treated equally and assigned equal weight. But a weighted average assigns weights that determine in advance the relative importance of each data point. In calculating a **weighted average**, each number in the data set is multiplied by a predetermined weight before the final calculation is made.\n",
    "\n",
    "| Data point | Value | Weight | Weighted value |\n",
    "| --- | --- | --- | --- |\n",
    "| 1 | 10 | 2 | 20 |\n",
    "| 2 | 50 | 5 | 250 |\n",
    "| 3 | 40 | 3 | 120 |\n",
    "| **TOTAL** | 100 | 10 | 390 |\n",
    "| **Weighted Avg** |  |  | 39 |\n",
    "\n",
    "#### 1.3 Convolution - second explanation\n",
    "Given two weighted dice with following probability distribution:\n",
    "\n",
    "<center><img src=\"img/convolution_0.png\" alt=\"Two weighted dices\" width=\"800\" height=\"424\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 1.</b> Two unfair (weighted) dice </i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "Convolution would be applying one of the function over the other and getting as a result a new function with new probability distribution.\n",
    "<center><img src=\"img/convolution_1.png\" alt=\"Convolution of probability functions\" width=\"800\" height=\"191\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 2.</b> Convolution of probability functions </i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "In order to get the polynomial of the new function, the easiest would be to **FLIP** the second distribution (kernel).\n",
    "<center><img src=\"img/convolution_2.png\" alt=\"Flip the kernel\" width=\"400\" height=\"508\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 3.</b> Flip the second distribution (kernel) </i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "And now we can easily calculate each probability of the new function by executing a **dot product** between the respective terms and then slide the kernel to the right.\n",
    "<center><img src=\"img/convolution_3.png\" alt=\"Multiply and slide\" width=\"800\" height=\"423\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 4.</b> Multiply and slide right </i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "So, we end up with next formula.\n",
    "<center><img src=\"img/convolution_4.png\" alt=\"Convolution formula\" width=\"800\" height=\"436\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 5.</b> Convolution formula</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339d8604",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.4 Formula\n",
    "* The **discrete** formula looks like this:\n",
    "```\n",
    "y[n] = Σ x[k] * h[n - k]\n",
    "```\n",
    "or more formally:\n",
    "$$[f*g](s) = \\sum f(x) \\cdot g(s-x) $$\n",
    "\n",
    "Considering the general rule of thumb:\n",
    "$$\\sum \\text{... } \\rightarrow \\int \\text{... }dx$$\n",
    "\n",
    "* The **continious** formula would be:\n",
    "\n",
    "$$[f*g](s) = \\int_{-\\infty}^{\\infty} f(x) \\cdot g(s-x) dx$$\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "It’s easiest if you assume one of the functions is a probability density function $P$ centered at the origin. Then the convolution of $P$ with a function $Q$ at each $x$ is the weighted average of $Q$, using $P$ as the weight function centered at $x$. This clearly creates a **smooth approximation** of $Q$ where the random noise in $Q$ is averaged out.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d43bfb7",
   "metadata": {},
   "source": [
    "# 2. Convolution operation\n",
    "\n",
    "Convolution between two matrices is a simple operation. You simply need to multiply the `input` matrix to a smaller `kernel` matrix in a specific way.\n",
    "\n",
    "\n",
    "But before that, you need to **flip** the kernel (i.e. reflect its content across the center).\n",
    "\n",
    "* NB: If not flipped, then we are not doing a **convolution**, but a **cross-correlation**.\n",
    "\n",
    "<center><img src=\"img/cnn_0.png\" alt=\"Convolution between two matrices\" width=\"600\" height=\"262\" /></center>\n",
    "<center><img src=\"img/cnn_1.png\" alt=\"Convolution between two matrices\" width=\"600\" height=\"259\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 6.</b> Convolution between two matrices</i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "We start from the upper-left corner of the `input` matrix. And we multiply each cell from the `input` to the corresponding cell into the `kernel` matrix. And we sum the result. This way we calculate the first cell of the `output` matrix.\n",
    "<center><img src=\"img/cnn_2.png\" alt=\"Multiply a submatrix from the `input` to the `kernel`\" width=\"600\" height=\"372\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 7.</b> Multiply a submatrix from the `input` to the `kernel`</i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "Then we slide the window to the right and calculate the next `output` cell.\n",
    "<center><img src=\"img/cnn_3.png\" alt=\"Slide the calculation window to the right\" width=\"600\" height=\"362\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 8.</b> Slide the calculation window to the right</i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "Once we can't slide more to the right, we go one row down and start over from the leftest cell.\n",
    "<center><img src=\"img/cnn_4.png\" alt=\"One row down and start again from the leftest cell\" width=\"600\" height=\"371\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 9.</b> One row down and start again from the leftest cell</i></p>\n",
    "\n",
    "<br/>\n",
    "\n",
    "* **Size of the output**\n",
    "\n",
    "The size of the output matrix is calculated as:\n",
    "$$ O = I - K + 1 $$\n",
    "where $I$ is the size of the `input` matrix and $K$ is the size of the `kernel` matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c217bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlate2d(image: np.ndarray, kernel: np.ndarray, mode: str = 'valid') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute the correlation of the image with the kernel.\n",
    "    The correlation is a measure of how similar two signals are.\n",
    "    In the context of image processing, the correlation is used to find the features in the image.\n",
    "    The correlation is calculated by multiplying the kernel with the image cell by cell and summing the result.\n",
    "    The output is a matrix of the same size as the image.\n",
    "    The mode parameter determines the shape of the output matrix.\n",
    "    - 'full' mode: the output matrix is the same size as the image.\n",
    "    - 'valid' mode: the output matrix is the same size as the image minus the kernel size.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The input image.\n",
    "        kernel (np.ndarray): The kernel.\n",
    "        mode (str): The mode of the correlation.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The output matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the shape of the kernel and image\n",
    "    m, n = kernel.shape\n",
    "    y, x = image.shape\n",
    "\n",
    "    # CASE 1: Full mode - output shape is (y + m - 1, x + n - 1)\n",
    "    if mode == 'valid':\n",
    "        # SLOW IMPLEMENTATION (not vectorized)\n",
    "        # for i in range(y - m + 1):\n",
    "        #     for j in range(x - n + 1):\n",
    "        #         output[i, j] = (image[i:i+m, j:j+n] * kernel).sum()\n",
    "\n",
    "        # FAST IMPLEMENTATION (vectorized)\n",
    "        output = einsum_submatrices(image, kernel, x-n+1, y-m+1, m, n)\n",
    "    \n",
    "    # CASE 2: Valid mode - output shape is (y - m + 1, x - n + 1)\n",
    "    elif mode == 'full':\n",
    "        # Add padding to the input image\n",
    "        image = np.pad(image, ((m-1, m-1), (n-1, n-1)), mode='constant', constant_values=0)\n",
    "        output = einsum_submatrices(image, kernel, x+n-1, y+m-1, m, n)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid mode: {mode}\")\n",
    "    return output\n",
    "\n",
    "def einsum_submatrices(image: np.ndarray, kernel: np.ndarray, width: int, height: int, m: int, n: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate submatrices of the image in order to use np.einsum.\n",
    "    The submatrices are generated by sliding the kernel over the image.\n",
    "    The submatrices are then multiplied with the kernel and the result is summed.\n",
    "    The result is a matrix of the same size as the image.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The input image.\n",
    "        kernel (np.ndarray): The kernel.\n",
    "        width (int): The width of the output matrix.\n",
    "        height (int): The height of the output matrix.\n",
    "        m (int): The number of rows of the kernel.\n",
    "        n (int): The number of columns of the kernel.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    submatrices = []\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            submatrices.append(image[i:i+m, j:j+n])\n",
    "    submatrices = np.array(submatrices)\n",
    "    submatrices = submatrices.reshape(height, width, m, n)\n",
    "    # Multiply the submatrices with the kernel\n",
    "    # np.einsum is a function that allows you to perform a dot product between two arrays.\n",
    "    # It is a more efficient way to perform the dot product than using a for loop.\n",
    "    # It is also more readable and concise.\n",
    "    # Generate submatrices of the image in order to use np.einsum\n",
    "    return np.einsum('ijkl,kl->ij', submatrices, kernel)\n",
    "\n",
    "def convolve2d(image: np.ndarray, kernel: np.ndarray, mode: str = 'valid') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convolve the image with the kernel.\n",
    "    \"\"\"\n",
    "    # Flip the kernel\n",
    "    kernel = np.flip(kernel)\n",
    "    return correlate2d(image, kernel, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328ddd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4 -4]\n",
      " [-4 -4]]\n",
      "[[4 4]\n",
      " [4 4]]\n",
      "\n",
      "[[-1 -2 -3  0]\n",
      " [-4 -4 -4  3]\n",
      " [-7 -4 -4  6]\n",
      " [ 0  7  8  9]]\n",
      "[[ 1  2  3  0]\n",
      " [ 4  4  4 -3]\n",
      " [ 7  4  4 -6]\n",
      " [ 0 -7 -8 -9]]\n"
     ]
    }
   ],
   "source": [
    "test_input = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "])\n",
    "\n",
    "# Kernel (filter)\n",
    "test_kernel = np.array([\n",
    "    [1, 0],\n",
    "    [0, -1]\n",
    "])\n",
    "\n",
    "print(correlate2d(test_input, test_kernel, mode='valid'))\n",
    "print(convolve2d(test_input, test_kernel, mode='valid'))\n",
    "print('')\n",
    "print(correlate2d(test_input, test_kernel, mode='full'))\n",
    "print(convolve2d(test_input, test_kernel, mode='full'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d10673",
   "metadata": {},
   "source": [
    "# 3. Convolutional Neural Network\n",
    "\n",
    "#### 3.1 Convolutional layer\n",
    "\n",
    "* **The input** is a 3-dimensional block of data (e.g. image tensor). In this case the depth is 3.\n",
    "* **The weights** are organized as kernels (a 3-dimensional block with the same depth as the input). The layer may have one or multiple kernels.\n",
    "* **The bias matrices** have the same shape as the outputs. The number of biases is equal to the number of kernels in the layer.\n",
    "* **The output** is a 3-dimensional block of data. The depth of the output is the same as the number of kernels.\n",
    "\n",
    "<center><img src=\"img/cnn_5.png\" alt=\"Convolutional layer with 2 kernels\" width=\"800\" height=\"404\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 10.</b> Convolutional layer with 2 kernels</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86746bcd",
   "metadata": {},
   "source": [
    "First, let's create an abstract class, which will further be used for any kind of layers in our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a83db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        # TODO: return output\n",
    "        pass\n",
    "\n",
    "    def backward(self, output_gradient: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        # TODO: update parameters and return input gradient\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d7828",
   "metadata": {},
   "source": [
    "Now, let's create the **convolutional layer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b4993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, kernel_size: int, num_of_kernels: int):\n",
    "        \"\"\"\n",
    "        Initialize the convolutional layer.\n",
    "        The layer will be initialized with random weights and biases.\n",
    "\n",
    "        The shape of the output is calculated as:\n",
    "         * output_shape = (num_of_kernels, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
    "         * kernel_shape = (num_of_kernels, input_depth, kernel_size, kernel_size)\n",
    "         * biases_shape = (output_shape)\n",
    "\n",
    "        Args:\n",
    "            input_shape: tuple, shape of the input data (depth, height, width)\n",
    "            kernel_size: int, size of the kernel (e.g. 4 for 4x4 kernel)\n",
    "            num_of_kernels: int, number of kernels in the layer (e.g. 2 for 2 kernels)\n",
    "        \"\"\"\n",
    "        input_depth, input_height, input_width = input_shape                            # (e.g. 3, 28, 28)\n",
    "        self.num_of_kernels = num_of_kernels                                            # (e.g. 2)\n",
    "        self.input_shape = input_shape                                                  # (e.g. 3, 28, 28)\n",
    "        self.kernel_shape = (num_of_kernels, input_depth, kernel_size, kernel_size)     # (e.g. 2, 3, 4, 4)\n",
    "        self.output_shape = (num_of_kernels, input_height - kernel_size + 1, input_width - kernel_size + 1) # (e.g. 2, 25, 25)\n",
    "\n",
    "        # Generate random weights and biases\n",
    "        self.kernels = np.random.randn(*self.kernel_shape)  # (e.g. 2, 3, 4, 4)\n",
    "        self.biases = np.random.randn(*self.output_shape)   # (e.g. 2, 25, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d7d1d",
   "metadata": {},
   "source": [
    "#### 3.2 Forward propagation\n",
    "**How the output is produced?**\n",
    "\n",
    "Take each matrix in the first kernel and compute the cross-correlation with the input data. Sum the three results and add up the first bias. This will produce the first output.\n",
    "\n",
    "\n",
    "<center><img src=\"img/cnn_6.png\" alt=\"Convolutional layer - how the output is produced\" width=\"800\" height=\"467\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 11.</b> Convolutional layer - how the output is produced</i></p>\n",
    "\n",
    "After that go on in the same manner for the next cells in this output matrix.\n",
    "\n",
    "\n",
    "Likewise, the second output is calculated by cross-correlating the input with the second kernel and second bias.\n",
    "\n",
    "\n",
    "<center><img src=\"img/cnn_7.png\" alt=\"Convolutional layer - the second output is produced in the same way, but using the second kernel\" width=\"800\" height=\"468\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 12.</b> Convolutional layer - the second output is produced in the same way, but using the second kernel</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47243107",
   "metadata": {},
   "source": [
    "We can simplify the formula to:\n",
    "$$Y_1 = B_1 + X_1 \\star K_{11} + X_2 \\star K_{12} + X_3 \\star K_{13} $$\n",
    "$$Y_2 = B_2 + X_2 \\star K_{21} + X_2 \\star K_{22} + X_3 \\star K_{23} $$\n",
    "$$ \\vdots $$\n",
    "$$Y_d = B_d + X_1 \\star K_{d1} + X_2 \\star K_{d2} + X_3 \\star K_{d3} $$\n",
    "\n",
    "Where $d$ is the the number of kernels (hence the depth of the outputs).\n",
    "\n",
    "\n",
    "\n",
    "<center><img src=\"img/cnn_8.png\" alt=\"Convolutional layer - the output formula (simplified)\" width=\"400\" height=\"227\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 13.</b> Convolutional layer - the output formula (simplified)</i></p>\n",
    "\n",
    "And if we generalize the shape of the input, we come up with following formula:\n",
    "\n",
    "$$Y_d = B_d + X_1 \\star K_{d1} + X_2 \\star K_{d2} + \\dots + X_n \\star K_{dn} $$\n",
    "\n",
    "or\n",
    "\n",
    "$$ Y_i = B_i + \\sum_{j=1}^{n}{X_j \\star K_{ij}} \\text{  ,  } i = 1 \\dots d$$\n",
    "\n",
    "Where $n$ is the depth of the input and $d$ is the number of kernels.\n",
    "\n",
    "\n",
    "If we go further, we will see a similarity between a regular dense layer and a convolutional layer. The only difference is that in the dense layer we calculate **dot product** between **matrices of scalar values**, while here we calculate **cross-correlated dot product** between **matrices of matrices**. But in general the dense layer is a subtype of the convolutional layer.\n",
    "\n",
    "<center><img src=\"img/cnn_9.png\" alt=\"Convolutional layer looks the same as a dense layer\" width=\"800\" height=\"288\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 14.</b> Convolutional layer looks very similar to a regular dense layer</i></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76ea1763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Forward pass through the convolutional layer.\n",
    "        - The input is a 3D tensor (e.g. image tensor).\n",
    "        - The output is a 3D tensor (e.g. feature map).\n",
    "\n",
    "    The formula is:\n",
    "        - Y_i = B_i + \\\\sum_{j=1}^{n}{X_j \\\\star K_{ij}}\n",
    "    where:\n",
    "        - Y_i is the output of the i-th kernel\n",
    "        - B_i is the bias of the i-th kernel\n",
    "        - X_j is the j-th depth of the input\n",
    "        - K_{ij} is the j-th depth of the i-th kernel\n",
    "        - n is the number of depths of the input\n",
    "\n",
    "    Args:\n",
    "        input: np.ndarray, input tensor (e.g. image tensor)\n",
    "    Returns:\n",
    "        np.ndarray, output tensor (e.g. feature map)\n",
    "    \"\"\"\n",
    "    self.input = input\n",
    "    self.output = np.copy(self.biases)\n",
    "\n",
    "    # For each kernel (e.g. 2)\n",
    "    for i in range(self.number_of_kernels): \n",
    "        # For each depth of the input (e.g. 3)\n",
    "        for j in range(self.input_shape[0]):\n",
    "            # The formula is:\n",
    "            # - output[i] += input[j] * kernels[i, j]\n",
    "            # where:\n",
    "            # - output[i] is the output of the i-th kernel\n",
    "            # - input[j] is the j-th depth of the input\n",
    "            # - kernels[i, j] is the j-th depth of the i-th kernel\n",
    "            # - mode='valid' is the mode of the correlation operation\n",
    "            self.output[i] += correlate2d(self.input[j], self.kernels[i, j], mode='valid')\n",
    "\n",
    "    # Return the output of the layer\n",
    "    return self.output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1961a8c9",
   "metadata": {},
   "source": [
    "#### 3.3 Backward propagation\n",
    "\n",
    "We need to calculate the following derivatives:\n",
    "$$\\frac{dJ}{dK_{ij}}, \\frac{dJ}{dB_i}, \\frac{dJ}{dX_j} $$\n",
    "\n",
    "And after applying several *chain rules* and some math mojo we come up with next formulas:\n",
    "$$\\frac{dJ}{dK_{ij}} = X_j \\star \\frac{dJ}{dY_{i}}$$\n",
    "$$\\frac{dJ}{dB_i} = \\frac{dJ}{dY_{i}}$$\n",
    "$$\\frac{dJ}{dX_j} = \\sum_{i=1}^d {\\frac{dJ}{dY_{i}} \\ast_{full} }K $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63c4662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(self, output_gradient: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Backward pass through the convolutional layer.\n",
    "\n",
    "    Args:\n",
    "        output_gradient: np.ndarray, the gradient of the output (e.g. [[1, 2, 3], [4, 5, 6]])\n",
    "        learning_rate: float, the learning rate\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray, the gradient of the input (e.g. [1, 2, 3, 4, 5, 6])\n",
    "    \"\"\"\n",
    "    kernels_gradient = np.zeros(self.kernel_shape)\n",
    "    input_gradient = np.zeros(self.input_shape)\n",
    "\n",
    "    for i in range(self.num_of_kernels):\n",
    "        for j in range(self.input_shape[0]): # input depth\n",
    "            kernels_gradient[i, j] = correlate2d(self.input[j], output_gradient[i], mode='valid')\n",
    "            input_gradient[j] += convolve2d(output_gradient[i], self.kernels[i, j], mode='full')\n",
    "\n",
    "    self.kernels -= learning_rate * kernels_gradient\n",
    "    self.biases -= learning_rate * output_gradient\n",
    "\n",
    "    return input_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c4790b",
   "metadata": {},
   "source": [
    "So, finally, the class will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d63ed094",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, kernel_size: int, num_of_kernels: int):\n",
    "        \"\"\"\n",
    "        Initialize the convolutional layer.\n",
    "        The layer will be initialized with random weights and biases.\n",
    "\n",
    "        The shape of the output is calculated as:\n",
    "         * output_shape = (num_of_kernels, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
    "         * kernel_shape = (num_of_kernels, input_depth, kernel_size, kernel_size)\n",
    "         * biases_shape = (output_shape)\n",
    "\n",
    "        Args:\n",
    "            input_shape: tuple, shape of the input data (depth, height, width)\n",
    "            kernel_size: int, size of the kernel (e.g. 4 for 4x4 kernel)\n",
    "            num_of_kernels: int, number of kernels in the layer (e.g. 2 for 2 kernels)\n",
    "        \"\"\"\n",
    "        input_depth, input_height, input_width = input_shape                            # (e.g. 3, 28, 28)\n",
    "        self.num_of_kernels = num_of_kernels                                            # (e.g. 2)\n",
    "        self.input_shape = input_shape                                                  # (e.g. 3, 28, 28)\n",
    "        self.kernel_shape = (num_of_kernels, input_depth, kernel_size, kernel_size)     # (e.g. 2, 3, 4, 4)\n",
    "        self.output_shape = (num_of_kernels, input_height - kernel_size + 1, input_width - kernel_size + 1) # (e.g. 2, 25, 25)\n",
    "\n",
    "        # Generate random weights and biases\n",
    "        self.kernels = np.random.randn(*self.kernel_shape)  # (e.g. 2, 3, 4, 4)\n",
    "        self.biases = np.random.randn(*self.output_shape)   # (e.g. 2, 25, 25)\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Forward pass through the convolutional layer.\n",
    "            - The input is a 3D tensor (e.g. image tensor).\n",
    "            - The output is a 3D tensor (e.g. feature map).\n",
    "\n",
    "        The formula is:\n",
    "            - Y_i = B_i + \\\\sum_{j=1}^{n}{X_j \\\\star K_{ij}}\n",
    "        where:\n",
    "            - Y_i is the output of the i-th kernel\n",
    "            - B_i is the bias of the i-th kernel\n",
    "            - X_j is the j-th depth of the input\n",
    "            - K_{ij} is the j-th depth of the i-th kernel\n",
    "            - n is the number of depths of the input\n",
    "\n",
    "        Args:\n",
    "            input: np.ndarray, input tensor (e.g. image tensor)\n",
    "        Returns:\n",
    "            np.ndarray, output tensor (e.g. feature map)\n",
    "        \"\"\"\n",
    "        self.input = input\n",
    "        self.output = np.copy(self.biases) # Output = bias + sum(input * kernel)\n",
    "\n",
    "        # For each kernel (e.g. 2)\n",
    "        for i in range(self.num_of_kernels): \n",
    "            # For each depth of the input (e.g. 3)\n",
    "            for j in range(self.input_shape[0]):\n",
    "                # The formula is:\n",
    "                # - output[i] += input[j] * kernels[i, j]\n",
    "                # where:\n",
    "                # - output[i] is the output of the i-th kernel\n",
    "                # - input[j] is the j-th depth of the input\n",
    "                # - kernels[i, j] is the j-th depth of the i-th kernel\n",
    "                # - mode='valid' is the mode of the correlation operation\n",
    "                self.output[i] += correlate2d(self.input[j], self.kernels[i, j], mode='valid')\n",
    "\n",
    "        # Return the output of the layer\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, output_gradient: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Backward pass through the convolutional layer.\n",
    "\n",
    "        Args:\n",
    "            output_gradient: np.ndarray, the gradient of the output (e.g. [[1, 2, 3], [4, 5, 6]])\n",
    "            learning_rate: float, the learning rate\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray, the gradient of the input (e.g. [1, 2, 3, 4, 5, 6])\n",
    "        \"\"\"\n",
    "        kernels_gradient = np.zeros(self.kernel_shape)\n",
    "        input_gradient = np.zeros(self.input_shape)\n",
    "\n",
    "        for i in range(self.num_of_kernels):\n",
    "            for j in range(self.input_shape[0]): # input depth\n",
    "                kernels_gradient[i, j] = correlate2d(self.input[j], output_gradient[i], mode='valid')\n",
    "                input_gradient[j] += convolve2d(output_gradient[i], self.kernels[i, j], mode='full')\n",
    "\n",
    "        self.kernels -= learning_rate * kernels_gradient\n",
    "        self.biases -= learning_rate * output_gradient\n",
    "\n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b8190c",
   "metadata": {},
   "source": [
    "# 4. Reshape Layer\n",
    "\n",
    "This layer is needed since the output of a **convolutional layer** is a 3D block. While typically at the end of a network we use **dense layers**, which take in a column vector as an input. Therefore, we need a mechanism that reshapes data, hence the **reshape layer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "071ac865",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(Layer):\n",
    "\n",
    "    def __init__(self, input_shape: tuple, output_shape: tuple):\n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Reshape the input to the output shape.\n",
    "\n",
    "        Args:\n",
    "            input: np.ndarray, the input to be reshaped (e.g. [1, 2, 3, 4, 5, 6])\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray, the reshaped input (e.g. [[1, 2, 3], [4, 5, 6]])\n",
    "        \"\"\"\n",
    "        return input.reshape(self.output_shape)\n",
    "\n",
    "    def backward(self, output_gradient: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Reshape the output gradient to the input shape.\n",
    "\n",
    "        Args:\n",
    "            output_gradient: np.ndarray, the gradient of the output (e.g. [[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray, the gradient of the input (e.g. [1, 2, 3, 4, 5, 6])\n",
    "        \"\"\"\n",
    "        return output_gradient.reshape(self.input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e481d0c",
   "metadata": {},
   "source": [
    "# 5. Dense layer\n",
    "We will add a standart **dense** layer, which you should already know from all other neural networks, covered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ef1bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.randn(output_size, input_size)\n",
    "        self.bias = np.random.randn(output_size, 1)\n",
    "\n",
    "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
    "        self.input = input\n",
    "        # Return the standard output of the layer (weights * input + bias)\n",
    "        return np.dot(self.weights, self.input) + self.bias\n",
    "\n",
    "    def backward(self, output_gradient: np.ndarray, learning_rate: float) -> np.ndarray:\n",
    "        # Calculate the weights gradient\n",
    "        weights_gradient = np.dot(output_gradient, self.input.T)\n",
    "        # Calculate the input gradient\n",
    "        input_gradient = np.dot(self.weights.T, output_gradient)\n",
    "        # Update the weights and bias\n",
    "        self.weights -= learning_rate * weights_gradient\n",
    "        self.bias -= learning_rate * output_gradient\n",
    "        return input_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a296a98",
   "metadata": {},
   "source": [
    "# 6. Cross Entropy Loss\n",
    "We'll prepare our **convolutional neural network** for classification task. Hence, we'll use the **cross entropy loss** formula.\n",
    "\n",
    "If this is the **actual** output of the network:\n",
    "$$ \\hat{Y} = \\begin{bmatrix}\\hat{y_1}\\\\\\hat{y_2}\\\\\\vdots\\\\\\hat{y_i}\\end{bmatrix}  ,  \\hat{y_i} \\in \\{0,1\\} $$\n",
    "\n",
    "And this is the **expected** one:\n",
    "$$ Y = \\begin{bmatrix}y_1\\\\y_2\\\\\\vdots\\\\y_i\\end{bmatrix} $$\n",
    "\n",
    "Then the **cross-entropy loss** formula would be:\n",
    "$$ J = -\\frac{1}{n} \\sum_{i=1}^{n} \\hat{y_i} log(y_i) + (1-\\hat{y_i}) log(1-y_i) $$\n",
    "\n",
    "Thus, the derivative of $J$ w.r.t to the **output** would be:\n",
    "$$ \\frac{dJ}{dY} = \\begin{bmatrix} \\frac{dJ}{dy_1} \\\\ \\frac{dJ}{dy_2} \\\\\\vdots\\\\ \\frac{dJ}{dy_i} \\end{bmatrix} \n",
    "= \\frac{1}{n} \\left(\\frac{1-\\hat{y_i}}{1-y_i} - \\frac{\\hat{y_i}}{y_i} \\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9b1a143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(Y_true: np.ndarray, Y_pred: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the cross-entropy loss.\n",
    "\n",
    "    Args:\n",
    "        Y_true: np.ndarray, the true labels (e.g. [0, 1, 0, 1, 0])\n",
    "        Y_pred: np.ndarray, the predicted labels (e.g. [0.1, 0.9, 0.1, 0.9, 0.1])\n",
    "\n",
    "    Returns:\n",
    "        float, the cross-entropy loss\n",
    "    \"\"\"\n",
    "    e = 1e-7 # Avoid log(0)\n",
    "    return -np.mean(Y_true * np.log(Y_pred + e) + (1 - Y_true) * np.log(1 - Y_pred + e))\n",
    "\n",
    "def cross_entropy_loss_derivative(Y_true: np.ndarray, Y_pred: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculate the derivative of the cross-entropy loss.\n",
    "\n",
    "    Args:\n",
    "        Y_true: np.ndarray, the true labels (e.g. [0, 1, 0, 1, 0])\n",
    "        Y_pred: np.ndarray, the predicted labels (e.g. [0.1, 0.9, 0.1, 0.9, 0.1])\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray, the derivative of the cross-entropy loss\n",
    "    \"\"\"\n",
    "    e = 1e-7 # Avoid division by zero\n",
    "    return ((1 - Y_true) / (1 - Y_pred + e) - Y_true / (Y_pred + e)) / np.size(Y_true) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a7df8a",
   "metadata": {},
   "source": [
    "# 7. Activation function\n",
    "In our case we would use a **sigmoid** function for activation. And let's pack it as a layer, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c5fc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation(Layer):\n",
    "    def __init__(self, activation, activation_derivative):\n",
    "        self.activation = activation\n",
    "        self.activation_derivative = activation_derivative\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        # Explanation:\n",
    "        # - self.input: the input of the layer\n",
    "        # - self.activation: the activation function\n",
    "        # - return: the output of the layer\n",
    "        return self.activation(self.input)\n",
    "\n",
    "    def backward(self, output_gradient, learning_rate):\n",
    "        # Explanation:\n",
    "        # - output_gradient: the gradient of the output of the layer\n",
    "        # - self.activation_derivative: the derivative of the activation function\n",
    "        # - self.input: the input of the layer\n",
    "        # - np.multiply: the element-wise multiplication of the output_gradient and the activation_derivative\n",
    "        # - return: the gradient of the input of the layer\n",
    "        return np.multiply(output_gradient, self.activation_derivative(self.input))\n",
    "    \n",
    "class Sigmoid(Activation):\n",
    "    def __init__(self):\n",
    "        def sigmoid(x: np.ndarray) -> np.ndarray:\n",
    "            \"\"\"\n",
    "            Calculate the sigmoid of a given input.\n",
    "            \"\"\"\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        def sigmoid_derivative(x: np.ndarray) -> np.ndarray:\n",
    "            \"\"\"\n",
    "            Calculate the derivative of the sigmoid of a given input.\n",
    "            \"\"\"\n",
    "            return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "        # Call the parent class constructor to initialize the activation and activation_derivative\n",
    "        super().__init__(sigmoid, sigmoid_derivative)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcabca37",
   "metadata": {},
   "source": [
    "# 8. Apply CNN to MNIST\n",
    "Now let's train our **convolutional neural network** over the popular MNIST database. Our goal would be to classify `0` and `1` handwritten images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1e302d",
   "metadata": {},
   "source": [
    "#### 8.1 Download and unpack data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b37f2efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Reading the csv files...\n",
      "4. Unpacking the data...\n",
      "\tX_train: (60000, 28, 28), X_test: (10000, 28, 28), Y_train: (60000,), Y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Create `data` folder, if it does not exist.\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.makedirs(\"data\")\n",
    "\n",
    "# STEP 2: Load the data from the server, unless the file exists.\n",
    "if not os.path.isfile(\"data/mnist.zip\"):\n",
    "    print(\"1. Downloading the mnist.zip file...\")\n",
    "    response = requests.get(\"https://www.kaggle.com/api/v1/datasets/download/oddrationale/mnist-in-csv\")\n",
    "    with open(\"data/mnist.zip\", \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "# STEP 3: Unpack the `mnist.zip` file, if it is not already unpacked.\n",
    "if not os.path.isfile(\"data/mnist/mnist_train.csv\"):\n",
    "    print(\"2. Unpacking the `mnist.zip` file...\")\n",
    "    with zipfile.ZipFile('data/mnist.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('data/mnist')\n",
    "\n",
    "# STEP 4: Read the csv files.\n",
    "print(\"3. Reading the csv files...\")\n",
    "X_train = np.loadtxt(\"data/mnist/mnist_train.csv\", delimiter=\",\", skiprows=1, dtype=np.uint8)\n",
    "X_test = np.loadtxt(\"data/mnist/mnist_test.csv\", delimiter=\",\", skiprows=1, dtype=np.uint8)\n",
    "\n",
    "# STEP 5: Unpack the data.\n",
    "print(\"4. Unpacking the data...\")\n",
    "# Extract the first column as the label.\n",
    "Y_train, Y_test = X_train[:, 0], X_test[:, 0]\n",
    "X_train, X_test = X_train[:, 1:], X_test[:, 1:]\n",
    "# Reshape from (60000, 784) to (60000, 28, 28)\n",
    "X_train = X_train.reshape(-1, 28, 28)\n",
    "X_test = X_test.reshape(-1, 28, 28)\n",
    "print(f\"\\tX_train: {X_train.shape}, X_test: {X_test.shape}, Y_train: {Y_train.shape}, Y_test: {Y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23534cae",
   "metadata": {},
   "source": [
    "#### 8.2 Preprocess the data\n",
    "\n",
    "Basic preprocessing is needed:\n",
    "* reshape from $(28, 28)$ to $(1, 28, 28)$ where $1$ is basically the depth (channels) of the image\n",
    "* normalize values from $[0, 255]$ to $[0, 1]$\n",
    "* **one-hot encode** the labels (the $Y$-values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64a1ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Preprocessing the data...\n",
      "\tX_train_processed: (1000, 1, 28, 28), Y_train_processed: (1000, 2, 1)\n",
      "\tX_test_processed: (1000, 1, 28, 28), Y_test_processed: (1000, 2, 1)\n",
      "6. Displaying the first and second images on one plot...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def one_hot_encode(Y: np.ndarray, num_classes: int):\n",
    "    \"\"\"\n",
    "    Encode output (a number in [0,9]) into a vector of size 10 (e.g. 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
    "\n",
    "    Args:\n",
    "        Y: np.ndarray (e.g. with shape (60000,))\n",
    "\n",
    "    Returns:\n",
    "        Y_encoded: np.ndarray (e.g. with shape (60000, 10))\n",
    "    \"\"\"\n",
    "    # Initialize a matrix of zeros with shape (len(Y), num_classes - e.g. (1000, 2))\n",
    "    Y_encoded = np.zeros((Y.shape[0], num_classes))\n",
    "    # For each row, set the corresponding column (feature) to 1 (e.g. [0, 1] for 1 and [1, 0] for 0)\n",
    "    for i in range(Y.shape[0]):\n",
    "        Y_encoded[i, Y[i]] = 1\n",
    "    # Return the encoded matrix\n",
    "    return Y_encoded\n",
    "\n",
    "def preprocess_data(X: np.ndarray, Y: np.ndarray, limit: int):\n",
    "    \"\"\"\n",
    "    Preprocess data for training a convolutional neural network.\n",
    "\n",
    "    Args:\n",
    "        X: np.ndarray (e.g. with shape (1000, 28, 28))\n",
    "        Y: np.ndarray (e.g. with shape (1000,))\n",
    "        limit: int\n",
    "\n",
    "    Returns:\n",
    "        X: np.ndarray (e.g. with shape (1000, 28 * 28, 1))\n",
    "        Y: np.ndarray (e.g. with shape (1000, 10, 1))\n",
    "    \"\"\"\n",
    "    # Limit only to 0 and 1 images.\n",
    "    zero_index = np.where(Y == 0)[0][:limit]\n",
    "    one_index = np.where(Y == 1)[0][:limit]\n",
    "    all_indices = np.concatenate((zero_index, one_index))\n",
    "    X, Y = X[all_indices], Y[all_indices]\n",
    "    # Reshape from (1000, 28, 28) to (1000, 1, 28, 28) since the CNN expects the depth to be the first dimension\n",
    "    X = X.reshape(len(X), 1, 28, 28)\n",
    "    # Normalize [0, 255] to [0, 1]\n",
    "    X = X.astype(\"float32\") / 255\n",
    "    # Encode output (a number in [0,9]) into a vector of size 10 (e.g. 3 will become [0, 0, 0, 1, 0, 0, 0, 0, 0, 0])\n",
    "    Y = one_hot_encode(Y, 2)\n",
    "    # Reshape from (1000, 2) to (1000, 2, 1) - i.e. to be a column vector, since this is what the dense layer expects as input\n",
    "    Y = Y.reshape(len(Y), 2, 1)\n",
    "    return X, Y\n",
    "\n",
    "print(\"5. Preprocessing the data...\")\n",
    "X_train_processed, Y_train_processed = preprocess_data(X_train, Y_train, 500)\n",
    "X_test_processed, Y_test_processed = preprocess_data(X_test, Y_test, 500)\n",
    "print(f\"\\tX_train_processed: {X_train_processed.shape}, Y_train_processed: {Y_train_processed.shape}\")\n",
    "print(f\"\\tX_test_processed: {X_test_processed.shape}, Y_test_processed: {Y_test_processed.shape}\")\n",
    "\n",
    "# Display the two random images\n",
    "print(\"6. Displaying the first and second images on one plot...\")\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(X_train_processed[0, 0], cmap=\"gray\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(X_train_processed[501, 0], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a4d041",
   "metadata": {},
   "source": [
    "#### 8.3 Train the network\n",
    "Finally, let's fit the model with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d34d7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(network, input):\n",
    "    output = input\n",
    "    for layer in network:\n",
    "        output = layer.forward(output)\n",
    "    return output\n",
    "\n",
    "def train(network, loss, loss_prime, x_train, y_train, epochs = 1000, learning_rate = 0.01, verbose = True):\n",
    "    error_history = []\n",
    "    for e in range(epochs):\n",
    "        error = 0\n",
    "        for x, y in zip(x_train, y_train):\n",
    "            # forward\n",
    "            output = predict(network, x)\n",
    "\n",
    "            # error\n",
    "            error += loss(y, output)\n",
    "\n",
    "            # backward\n",
    "            grad = loss_prime(y, output)\n",
    "            for layer in reversed(network):\n",
    "                grad = layer.backward(grad, learning_rate)\n",
    "\n",
    "        error /= len(x_train)\n",
    "        error_history.append(error)\n",
    "        if verbose:\n",
    "            print(f\"{e + 1}/{epochs}, error={error}\")\n",
    "    return error_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9201690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/30, error=4.062032611081474\n",
      "2/30, error=4.06765455264666\n",
      "3/30, error=1.6534429525252918\n",
      "4/30, error=0.10011097551026311\n",
      "5/30, error=0.0724010977075232\n",
      "6/30, error=0.04276172559855906\n",
      "7/30, error=0.03679493951711106\n",
      "8/30, error=0.030733110146614274\n",
      "9/30, error=0.025829035416100148\n",
      "10/30, error=0.02423218991159468\n",
      "11/30, error=0.022710173828918385\n",
      "12/30, error=0.019826122863330825\n",
      "13/30, error=0.01769763099582641\n",
      "14/30, error=0.016256228457090835\n",
      "15/30, error=0.015492728288722349\n",
      "16/30, error=0.014175674926440824\n",
      "17/30, error=0.012926192885971785\n",
      "18/30, error=0.011868182904904474\n",
      "19/30, error=0.010917078469518402\n",
      "20/30, error=0.01009680530428993\n",
      "21/30, error=0.009321666002527\n",
      "22/30, error=0.008647685506260492\n",
      "23/30, error=0.008088089534883802\n",
      "24/30, error=0.007487191828861348\n",
      "25/30, error=0.0068566120968823205\n",
      "26/30, error=0.0062273286587424415\n",
      "27/30, error=0.0056267759480778615\n",
      "28/30, error=0.005072000443928607\n",
      "29/30, error=0.004570612257780241\n",
      "30/30, error=0.004128739104251192\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# neural network\n",
    "network = [\n",
    "    Convolutional((1, 28, 28), 3, 5),       # Convolutional layer with 5 kernels of size 3x3\n",
    "    Sigmoid(),                              # We always use an activation function after a convolutional layer\n",
    "    Reshape((5, 26, 26), (5 * 26 * 26, 1)), # Reshape the output of the convolutional layer to a 2D array\n",
    "    Dense(5 * 26 * 26, 2),                  # Dense layer with 2 output neurons (0 or 1)\n",
    "    Sigmoid()                               # We always use an activation function after a dense layer\n",
    "]\n",
    "\n",
    "# train\n",
    "loss_history = train(\n",
    "    network,\n",
    "    cross_entropy_loss,\n",
    "    cross_entropy_loss_derivative,\n",
    "    X_train_processed,\n",
    "    Y_train_processed,\n",
    "    epochs=30,\n",
    "    learning_rate=0.015\n",
    ")\n",
    "\n",
    "# Plot the loss history\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "568771d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.5%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test\n",
    "predictions = []\n",
    "actuals = []\n",
    "for x, y in zip(X_test_processed, Y_test_processed):\n",
    "    output = predict(network, x)\n",
    "    # Convert output vector to a scalar value of 0 or 1\n",
    "    predictions.append(np.argmax(output))\n",
    "    actuals.append(np.argmax(y))\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "true_positives = sum(1 for p, y in zip(predictions, actuals) if p == 1 and y == 1)\n",
    "true_negatives = sum(1 for p, y in zip(predictions, actuals) if p == 0 and y == 0)\n",
    "false_positives = sum(1 for p, y in zip(predictions, actuals) if p == 1 and y == 0)\n",
    "false_negatives = sum(1 for p, y in zip(predictions, actuals) if p == 0 and y == 1)\n",
    "confusion_matrix = np.array([[true_positives, false_positives], [false_negatives, true_negatives]])\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {(true_positives + true_negatives)*100 / len(X_test_processed)}%\")\n",
    "plt.matshow(confusion_matrix, cmap=\"Greens\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.xticks([0, 1], [0, 1], position=(0, -0.1))\n",
    "for (x, y), value in np.ndenumerate(confusion_matrix):\n",
    "    plt.text(x, y, f\"{value:.2f}\", va=\"center\", ha=\"center\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f07d6",
   "metadata": {},
   "source": [
    " * **NB**: The **random weight generation** at the beginning could harm the training results. Sometimes the starting point leads to a suboptimal **local bottom** and the model can't get out of it with current implementation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
