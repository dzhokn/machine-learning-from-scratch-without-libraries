{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Neural Network?\n",
    "\n",
    "A neural network is a simplified computational model inspired by the way the human brain processes information. While not biologically precise, it mimics key learning mechanisms observed in neural systems. The brain consists of a vast network of neurons connected by synapses, which vary in **strength**. Stronger connections, formed through **repeated activation**, facilitate faster and more efficient signal transmission. For instance, touching a hot pan triggers a learned response via a well-established neural pathway that prompts immediate withdrawal. Similarly, neural networks in ML strengthen certain connections - represented by weights - through repeated exposure and learning, **favoring pathways that lead to more accurate predictions**.\n",
    "\n",
    "This is a highly simplified explanation, but hopefully it helps you understand the basic concept."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Neuron?\n",
    "\n",
    "Now let’s see how exactly a single neuron operates.\n",
    "<center><img src=\"img/neural_network_2a.png\" alt=\"Neural Network Basic Layers\" width=\"395\" height=\"390\" /></center>\n",
    "<p style=\"text-align: center; font-size: small;\"><i><b>Figure 1.</b> How single neuron operates</i></p>\n",
    "\n",
    "$$ H = x_1*w_1 + x_2*w_2 + x_3*w_3 + b $$\n",
    "\n",
    "Here we take the example of what’s going on with a **single node** in the network. \n",
    "\n",
    "* $x_i$ are the **input values**.\n",
    "* $w_i$ are the **weights** that express the importance of each $x_i$ input value for the ouput.\n",
    "* $b$ is a **constant** bias. Bias is essentially a weight without an input term. It’s useful for having an **extra bit of adjustability** which is not dependant on the weights.\n",
    "* $H$ is the **final output value**.\n",
    "\n",
    "So finally, the output value of this node will be:\n",
    "\n",
    "$$ (0.8 \\times 0.3) + (0.1 \\times 0.5) + (0.3 \\times 0.6) + 0.1 = 0.24 + 0.05 + 0.18 + 0.1 = 0.57$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "A Perceptron is a basic, **single-layer** neural network used for binary classification. \n",
    "\n",
    "* **Structure**: Consists of a single layer of neurons (or perceptrons). \n",
    "* **Function**: Can only learn linear decision boundaries, meaning it can only classify data that can be separated by a straight line. \n",
    "* **Training**: Uses a simple learning algorithm (Perceptron learning algorithm) that adjusts weights based on errors in classification. \n",
    "* **Limitations**: Cannot solve non-linear problems like the XOR problem. \n",
    "\n",
    "## Implementation\n",
    "Now let's implement a basic perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's implement the multiplication between weights and $x_i$ values.\n",
    "\n",
    "$$ H = x_1*w_1 + x_2*w_2 + x_3*w_3 + b $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_sum(X: np.ndarray, w: np.ndarray, b: float) -> float:\n",
    "    return np.dot(X, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement a prediction function which calculates an output prediction (based on current $w_i$ and $b$ values). We will use $0$ as a threshold between the positive and negative answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X: np.ndarray, w: np.ndarray, b: float) -> float:\n",
    "    H = weighted_sum(X, w, b)\n",
    "    return np.where(H >= 0.5, 1, 0) # Binary classification (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's implement a function that calculates the error between **predicted** and **actual** value. The learning rate is usually a small number between $0.001$ and $0.1$ that helps us iteratively with small steps to improve the **weights** and **bias** coefficients during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(y_true: np.ndarray, y_pred: np.ndarray, learning_rate: float) -> float:\n",
    "    return learning_rate * (y_true - y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course we need to have methods that update the **weights** and **bias** coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(w: np.ndarray, x: np.ndarray, error: float) -> np.ndarray:\n",
    "    return w + error * x\n",
    "\n",
    "def update_bias(b: float, error: float) -> float:\n",
    "    return b + error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to add a method that executes the Perceptron training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(X: np.ndarray, Y: np.ndarray, w: np.ndarray, b: float, learning_rate: float, epochs: int) -> tuple[np.ndarray, float]:\n",
    "    for _ in range(epochs):\n",
    "        total_error = 0\n",
    "        for i in range(len(X)):\n",
    "            y_pred = predict(X[i], w, b)\n",
    "            error = calculate_error(Y[i], y_pred, learning_rate)\n",
    "            w = update_weights(w, X[i], error)\n",
    "            b = update_bias(b, error)\n",
    "            total_error += error\n",
    "        print(f\"Epoch {_ + 1} - Total Error: {total_error}\")\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let's test what we've created. We would like to work on the AND Gate problem. The gate returns if and only if both inputs are true.\n",
    "\n",
    "| $x_1$ | $x_2$ | $y$ |\n",
    "| --- | --- | --- |\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 0 |\n",
    "| 1 | 0 | 0 |\n",
    "| 1 | 1 | 1 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Total Error: 0.1\n",
      "Epoch 2 - Total Error: 0.1\n",
      "Epoch 3 - Total Error: 0.0\n",
      "Final weights: [0.2 0.2] and final bias: 0.2\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = np.array([0, 0, 0, 1])\n",
    "\n",
    "# Create zero weights and bias\n",
    "w = np.zeros(2)\n",
    "b = 0\n",
    "learning_rate = 0.1\n",
    "epochs = 3\n",
    "\n",
    "w, b = train_perceptron(X, Y, w, b, learning_rate, epochs)\n",
    "\n",
    "print(f\"Final weights: {w} and final bias: {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We needed only 3 epochs to reach a zero error. The optimal weigts and bias are:\n",
    "$$w_1 = 0.2 $$\n",
    "$$w_2 = 0.2 $$\n",
    "$$b = 0.2 $$\n",
    "\n",
    "In this case the model comply with the GATE rule (note that our threshold value is $0.5$ - our perceptron considers everything below this value as $0$):\n",
    "\n",
    "| $x_1$ | $x_2$ | $H$ | $y$ |\n",
    "| --- | ---| --- | --- |\n",
    "| 0 | 0 | **0.2** | 0 |\n",
    "| 0 | 1 | **0.4** | 0 |\n",
    "| 1 | 0 | **0.4** | 0 |\n",
    "| 1 | 1 | **0.6** | 1 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
